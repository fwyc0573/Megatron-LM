using world size: 1, data-parallel size: 1, context-parallel size: 1 tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
using torch.float32 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_fully_parallel_save ........................ False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 1
  data_path ....................................... ['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  delay_grad_reduce ............................... True
  delay_param_gather .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format ................................ torch_dist
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  do_trace ........................................ True
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_one_logger ............................... False
  encoder_num_layers .............................. 80
  encoder_seq_length .............................. 2048
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  fake_dp ......................................... 1
  fake_gpus_per_node .............................. 8
  fake_local_rank ................................. 0
  fake_pp ......................................... 8
  fake_tp ......................................... 8
  fake_world_size ................................. 64
  fake_wrank ...................................... 0
  ffn_hidden_size ................................. 32768
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 2
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 8192
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  is_scaling_mode ................................. True
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 100
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  main_tokenizer_type ............................. GPT2BPETokenizer
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/gpt2-merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_dropping .............................. False
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  nsight_start .................................... 10
  num_attention_heads ............................. 64
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 80
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_entity ............................... hwinf_dcm
  one_logger_project .............................. e2e-tracking
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float32
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  spec ............................................ None
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  trace_start ..................................... 10
  train_data_path ................................. None
  train_iters ..................................... 10
  train_samples ................................... None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_mcore_models ................................ True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/gpt2-vocab.json
  vocab_size ...................................... 3200
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 1
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 1
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.061 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
proj187:3289979:3289979 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ens81f0
proj187:3289979:3289979 [0] NCCL INFO NCCL_SOCKET_IFNAME set to ens81f0
proj187:3289979:3289979 [0] NCCL INFO Bootstrap : Using ens81f0:192.168.50.187<0>
proj187:3289979:3289979 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
proj187:3289979:3289979 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
proj187:3289979:3289979 NCCL CALL ncclGetUniqueId(0x9554de0dcbcf9f12)
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.18.6+cuda12.1
proj187:3289979:3289979 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7fd293400000
proj187:3289979:3290272 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
proj187:3289979:3290272 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ens81f0
proj187:3289979:3290272 [0] NCCL INFO NET/Socket : Using [0]ens81f0:192.168.50.187<0>
proj187:3289979:3290272 [0] NCCL INFO Using network Socket
proj187:3289979:3290272 [0] NCCL INFO comm 0x90cf8f0 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x9554de0dcbcf9f12 - Init START
proj187:3289979:3290272 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3289979:3290272 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3289979:3290272 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3289979:3290272 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3289979:3290272 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3289979:3290272 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3289979:3290272 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3289979:3290272 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3289979:3290272 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3289979:3290272 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3289979:3290272 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3289979:3290272 [0] NCCL INFO ==========================================
proj187:3289979:3290272 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3289979:3290272 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3289979:3290272 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290272 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290272 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290272 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290272 [0] NCCL INFO Channel 00/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 01/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 02/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 03/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 04/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 05/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 06/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 07/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 08/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 09/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 10/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 11/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 12/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 13/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 14/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 15/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 16/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 17/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 18/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 19/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 20/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 21/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 22/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 23/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 24/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 25/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 26/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 27/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 28/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 29/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 30/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Channel 31/32 :    0
proj187:3289979:3290272 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3289979:3290272 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3289979:3290272 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3289979:3290272 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c00000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c00200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c00400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c00600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c00800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c00a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c00c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c00e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c01000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c01200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c01400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c01600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c01800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c01a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c01c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c01e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c02000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c02200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c02400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c02600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c02800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c02a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c02c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c02e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c03000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c03200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c03400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c03600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c03800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c03a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c03c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c03e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c04000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c04200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c04400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c04600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c04800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c04a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c04c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c04e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c05000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c05200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c05400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c05600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c05800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c05a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c05c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c05e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c06000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c06200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c06400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c06600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c06800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c06a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c06c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c06e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c07000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c07200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c07400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c07600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c07800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c07a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c07c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c07e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c08000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c08200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c08400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c08600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c08800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c08a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c08c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c08e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c09000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c09200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c09400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c09600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c09800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c09a00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c09c00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c09e00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0a000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0a200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0a400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0a600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0a800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0aa00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0ac00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0ae00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0b000
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0b200
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0b400
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0b600
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0b800
proj187:3289979:3290272 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0ba00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0bc00
proj187:3289979:3290272 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0be00
proj187:3289979:3290272 [0] NCCL INFO Connected all rings
proj187:3289979:3290272 [0] NCCL INFO Connected all trees
proj187:3289979:3290272 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3289979:3290278 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7fd278002f20
proj187:3289979:3290278 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-hkrJE2
proj187:3289979:3290278 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3289979:3290278 [0] NCCL INFO proxyProgressAsync opId=0x7fd2661b3480 op.type=1 op.reqBuff=0x7fd278000bb0 op.respSize=16 done
proj187:3289979:3290272 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fd2661b3480
proj187:3289979:3290272 [0] NCCL INFO recvOpId=0x7fd2661b3480 matches expected opId=0x7fd2661b3480
proj187:3289979:3290278 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3289979:3290272 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7fd278003160
proj187:3289979:3290278 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7fd258000000
proj187:3289979:3290278 [0] NCCL INFO proxyProgressAsync opId=0x7fd2661b3480 op.type=2 op.reqBuff=0x7fd278005cc0 op.respSize=0 done
proj187:3289979:3290272 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fd2661b3480
proj187:3289979:3290278 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3289979:3290272 [0] NCCL INFO recvOpId=0x7fd2661b3480 matches expected opId=0x7fd2661b3480
proj187:3289979:3290272 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7fd263c0c000
proj187:3289979:3290272 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7fd256000000
proj187:3289979:3290272 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7fd293400200
proj187:3289979:3290272 NCCL CALL ncclCommInitRank(0x90cf8f0, 1, 0x9554de0dcbcf9f12, 0, 0)
proj187:3289979:3290272 [0] NCCL INFO comm 0x90cf8f0 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x9554de0dcbcf9f12 - Init COMPLETE
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200200 recvbuff 0x7fd293200200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200200,7fd293200200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200000 recvbuff 0x7fd293200000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200000,7fd293200000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
>>> done with compiling and loading fused kernels. Compilation time: 0.880 seconds
/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/training/initialize.py:405: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200000 recvbuff 0x7fd293200000 count 1 datatype 8 op 3 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200000,7fd293200000,1,8,3,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
time to initialize megatron (seconds): 2.065
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200200 recvbuff 0x7fd293200200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200200,7fd293200200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
[after megatron is initialized] datetime: 2024-09-22 17:07:21 
mpu_info:MPUInfo:
	dp_size=1
	tp_size=8
	pp_size=8
	mp_size=64
	world_size=64
	dp_groups=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37], [38], [39], [40], [41], [42], [43], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63]]
	pp_groups=[[0, 8, 16, 24, 32, 40, 48, 56], [1, 9, 17, 25, 33, 41, 49, 57], [2, 10, 18, 26, 34, 42, 50, 58], [3, 11, 19, 27, 35, 43, 51, 59], [4, 12, 20, 28, 36, 44, 52, 60], [5, 13, 21, 29, 37, 45, 53, 61], [6, 14, 22, 30, 38, 46, 54, 62], [7, 15, 23, 31, 39, 47, 55, 63]]
	tp_groups=[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15], [16, 17, 18, 19, 20, 21, 22, 23], [24, 25, 26, 27, 28, 29, 30, 31], [32, 33, 34, 35, 36, 37, 38, 39], [40, 41, 42, 43, 44, 45, 46, 47], [48, 49, 50, 51, 52, 53, 54, 55], [56, 57, 58, 59, 60, 61, 62, 63]]
	mp_groups=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]]
	ep_groups=[[0, 56], [1, 57], [2, 58], [3, 59], [4, 60], [5, 61], [6, 62], [7, 63]]
	pep_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200400 recvbuff 0x7fd293200400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200400,7fd293200400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200200 recvbuff 0x7fd293200200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200200,7fd293200200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200400 recvbuff 0x7fd293200400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200400,7fd293200400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGetUniqueId(0xf7b4d92f16ec7ed7)
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7fd293470400
proj187:3289979:3290598 [0] NCCL INFO Using network Socket
proj187:3289979:3290598 [0] NCCL INFO comm 0xd1661f0 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xf7b4d92f16ec7ed7 - Init START
proj187:3289979:3290598 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3289979:3290598 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3289979:3290598 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3289979:3290598 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3289979:3290598 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3289979:3290598 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3289979:3290598 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3289979:3290598 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3289979:3290598 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3289979:3290598 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3289979:3290598 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3289979:3290598 [0] NCCL INFO ==========================================
proj187:3289979:3290598 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3289979:3290598 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3289979:3290598 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290598 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290598 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290598 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290598 [0] NCCL INFO Channel 00/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 01/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 02/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 03/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 04/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 05/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 06/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 07/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 08/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 09/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 10/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 11/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 12/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 13/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 14/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 15/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 16/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 17/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 18/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 19/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 20/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 21/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 22/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 23/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 24/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 25/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 26/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 27/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 28/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 29/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 30/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Channel 31/32 :    0
proj187:3289979:3290598 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3289979:3290598 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3289979:3290598 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3289979:3290598 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0e000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0e200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0e400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0e600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0e800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0ea00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0ec00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0ee00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0f000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0f200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0f400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0f600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0f800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c0fa00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c0fc00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c0fe00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c10000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c10200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c10400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c10600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c10800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c10a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c10c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c10e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c11000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c11200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c11400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c11600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c11800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c11a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c11c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c11e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c12000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c12200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c12400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c12600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c12800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c12a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c12c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c12e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c13000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c13200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c13400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c13600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c13800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c13a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c13c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c13e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c14000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c14200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c14400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c14600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c14800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c14a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c14c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c14e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c15000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c15200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c15400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c15600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c15800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c15a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c15c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c15e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c16000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c16200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c16400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c16600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c16800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c16a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c16c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c16e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c17000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c17200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c17400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c17600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c17800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c17a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c17c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c17e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c18000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c18200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c18400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c18600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c18800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c18a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c18c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c18e00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c19000
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c19200
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c19400
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c19600
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c19800
proj187:3289979:3290598 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c19a00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c19c00
proj187:3289979:3290598 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c19e00
proj187:3289979:3290598 [0] NCCL INFO Connected all rings
proj187:3289979:3290598 [0] NCCL INFO Connected all trees
proj187:3289979:3290598 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3289979:3290599 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7fd118002f20
proj187:3289979:3290599 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-8EDBku
proj187:3289979:3290599 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3289979:3290599 [0] NCCL INFO proxyProgressAsync opId=0x7fd11007f520 op.type=1 op.reqBuff=0x7fd118000bb0 op.respSize=16 done
proj187:3289979:3290598 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fd11007f520
proj187:3289979:3290599 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3289979:3290598 [0] NCCL INFO recvOpId=0x7fd11007f520 matches expected opId=0x7fd11007f520
proj187:3289979:3290598 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7fd118003160
proj187:3289979:3290599 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7fd10c000000
proj187:3289979:3290599 [0] NCCL INFO proxyProgressAsync opId=0x7fd11007f520 op.type=2 op.reqBuff=0x7fd118005cc0 op.respSize=0 done
proj187:3289979:3290598 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fd11007f520
proj187:3289979:3290599 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3289979:3290598 [0] NCCL INFO recvOpId=0x7fd11007f520 matches expected opId=0x7fd11007f520
proj187:3289979:3290598 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7fd263c1a000
proj187:3289979:3290598 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7fd10a000000
proj187:3289979:3290598 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7fd293470600
proj187:3289979:3290598 NCCL CALL ncclCommInitRank(0xd1661f0, 1, 0xf7b4d92f16ec7ed7, 0, 0)
proj187:3289979:3290598 [0] NCCL INFO comm 0xd1661f0 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xf7b4d92f16ec7ed7 - Init COMPLETE
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd27e000000 recvbuff 0x7fd27e000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd27e000000,7fd27e000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGetUniqueId(0x236ff9c00043ae8e)
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7fd293470800
proj187:3289979:3290603 [0] NCCL INFO Using network Socket
proj187:3289979:3290603 [0] NCCL INFO comm 0x19628f40 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x236ff9c00043ae8e - Init START
proj187:3289979:3290603 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3289979:3290603 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3289979:3290603 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3289979:3290603 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3289979:3290603 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3289979:3290603 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3289979:3290603 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3289979:3290603 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3289979:3290603 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3289979:3290603 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3289979:3290603 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3289979:3290603 [0] NCCL INFO ==========================================
proj187:3289979:3290603 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3289979:3290603 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3289979:3290603 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290603 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3289979:3290603 [0] NCCL INFO  0 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  1 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  2 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  3 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  4 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  5 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  6 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  7 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  8 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO  9 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 10 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 11 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 12 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 13 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 14 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO 15 : GPU/0
proj187:3289979:3290603 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3289979:3290603 [0] NCCL INFO Channel 00/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 01/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 02/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 03/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 04/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 05/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 06/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 07/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 08/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 09/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 10/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 11/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 12/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 13/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 14/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 15/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 16/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 17/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 18/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 19/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 20/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 21/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 22/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 23/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 24/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 25/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 26/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 27/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 28/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 29/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 30/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Channel 31/32 :    0
proj187:3289979:3290603 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3289979:3290603 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3289979:3290603 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3289979:3290603 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5c800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5ca00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5cc00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5ce00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5d000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5d200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5d400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5d600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5d800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5da00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5dc00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5de00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5e000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5e200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5e400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5e600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5e800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5ea00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5ec00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5ee00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5f000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5f200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5f400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5f600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5f800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c5fa00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c5fc00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c5fe00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c60000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c60200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c60400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c60600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c60800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c60a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c60c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c60e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c61000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c61200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c61400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c61600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c61800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c61a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c61c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c61e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c62000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c62200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c62400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c62600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c62800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c62a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c62c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c62e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c63000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c63200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c63400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c63600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c63800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c63a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c63c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c63e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c64000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c64200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c64400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c64600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c64800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c64a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c64c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c64e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c65000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c65200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c65400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c65600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c65800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c65a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c65c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c65e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c66000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c66200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c66400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c66600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c66800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c66a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c66c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c66e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c67000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c67200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c67400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c67600
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c67800
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c67a00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c67c00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c67e00
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c68000
proj187:3289979:3290603 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7fd263c68200
proj187:3289979:3290603 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7fd263c68400
proj187:3289979:3290603 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7fd263c68600
proj187:3289979:3290603 [0] NCCL INFO Connected all rings
proj187:3289979:3290603 [0] NCCL INFO Connected all trees
proj187:3289979:3290603 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3289979:3290604 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7fcc68002f20
proj187:3289979:3290604 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-jvFzI6
proj187:3289979:3290604 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3289979:3290604 [0] NCCL INFO proxyProgressAsync opId=0x7fcc5c07f520 op.type=1 op.reqBuff=0x7fcc68000bb0 op.respSize=16 done
proj187:3289979:3290603 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fcc5c07f520
proj187:3289979:3290603 [0] NCCL INFO recvOpId=0x7fcc5c07f520 matches expected opId=0x7fcc5c07f520
proj187:3289979:3290604 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3289979:3290603 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7fcc68003160
proj187:3289979:3290604 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7fcc58000000
proj187:3289979:3290604 [0] NCCL INFO proxyProgressAsync opId=0x7fcc5c07f520 op.type=2 op.reqBuff=0x7fcc68005cc0 op.respSize=0 done
proj187:3289979:3290603 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7fcc5c07f520
proj187:3289979:3290604 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3289979:3290603 [0] NCCL INFO recvOpId=0x7fcc5c07f520 matches expected opId=0x7fcc5c07f520
proj187:3289979:3290603 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7fd263c68800
proj187:3289979:3290603 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7fcc56000000
proj187:3289979:3290603 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7fd293470a00
proj187:3289979:3290603 NCCL CALL ncclCommInitRank(0x19628f40, 1, 0x236ff9c00043ae8e, 0, 0)
proj187:3289979:3290603 [0] NCCL INFO comm 0x19628f40 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x236ff9c00043ae8e - Init COMPLETE
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 0, finish warm up ...
rank_id = 0, input_tensor_shapes: []
rank:0,cuda fwd time: 114.8689956665039
rank:0, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.23,timestamp=4409474858.24,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409474865.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409474869.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.81,timestamp=4409474876.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409474880.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.93,timestamp=4409474887.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409474891.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409474897.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409474902.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409474909.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.66,timestamp=4409474913.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409474920.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409474925.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.83,timestamp=4409474932.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.44,timestamp=4409474937.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409474944.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409474948.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409474955.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.36,timestamp=4409474960.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.64,timestamp=4409474966.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409474971.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 0, finish FWD profile ...
rank:0, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.73,timestamp=4409474979.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.9,timestamp=4409474993.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409475002.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.9,timestamp=4409475016.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409475025.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409475039.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409475048.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409475062.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409475071.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409475085.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409475094.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409475107.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.16,timestamp=4409475116.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409475130.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.18,timestamp=4409475138.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.64,timestamp=4409475152.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409475161.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409475175.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409475184.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.9,timestamp=4409475198.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:0, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:0,optimizer_step time: 29.651968002319336
rank:0, finish optimizer.step profile ...
rank:0, Before memory release - Allocated: 17367403008, Reserved: 32520536064
rank:0, trace log has been written to txt...
rank:0, finish release GPU memory ...
rank:0, After memory release - Allocated: 8629306368, Reserved: 8780775424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200200 recvbuff 0x7fd293200200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200200,7fd293200200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd293200200 recvbuff 0x7fd293200200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd293200200,7fd293200200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcfe6000000 recvbuff 0x7fcfe6000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcfe6000000,7fcfe6000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 1, finish warm up ...
rank_id = 1, input_tensor_shapes: []
rank:1,cuda fwd time: 113.6015396118164
rank:1, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409476217.37,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.54,timestamp=4409476224.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409476229.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.05,timestamp=4409476235.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409476239.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409476246.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409476250.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409476257.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409476261.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409476268.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409476273.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409476279.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409476284.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409476290.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409476295.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409476301.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409476306.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409476313.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.54,timestamp=4409476318.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.93,timestamp=4409476324.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.42,timestamp=4409476329.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 1, finish FWD profile ...
rank:1, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409476337.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.03,timestamp=4409476351.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409476361.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409476375.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409476384.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409476398.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409476407.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409476420.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409476429.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409476443.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409476452.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.63,timestamp=4409476465.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409476474.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.63,timestamp=4409476488.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409476497.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409476510.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409476519.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409476533.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409476542.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409476557.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:1, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:1,optimizer_step time: 29.655040740966797
rank:1, finish optimizer.step profile ...
rank:1, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:1, trace log has been written to txt...
rank:1, finish release GPU memory ...
rank:1, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff800 recvbuff 0x7fd2933ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff800,7fd2933ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffa00 recvbuff 0x7fd2933ffa00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffa00,7fd2933ffa00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffc00 recvbuff 0x7fd2933ffc00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffc00,7fd2933ffc00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd27e000000 recvbuff 0x7fd27e000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd27e000000,7fd27e000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffc00 recvbuff 0x7fcff27ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffc00,7fcff27ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 2, finish warm up ...
rank_id = 2, input_tensor_shapes: []
rank:2,cuda fwd time: 118.84748840332031
rank:2, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409477568.78,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.44,timestamp=4409477575.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409477580.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.06,timestamp=4409477586.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409477591.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.04,timestamp=4409477597.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409477602.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409477608.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409477613.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409477619.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409477624.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409477630.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409477635.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409477642.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409477647.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409477653.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409477658.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409477665.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.54,timestamp=4409477669.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.94,timestamp=4409477676.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.03,timestamp=4409477686.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 2, finish FWD profile ...
rank:2, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.83,timestamp=4409477694.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.06,timestamp=4409477708.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409477717.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.99,timestamp=4409477730.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409477739.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409477753.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409477762.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409477776.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409477785.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409477799.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409477808.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409477821.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409477830.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409477844.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409477853.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409477866.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409477875.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409477889.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409477898.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409477912.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:2, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff800 recvbuff 0x7fd2933ff800 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff800,7fd2933ff800,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:2,optimizer_step time: 29.58336067199707
rank:2, finish optimizer.step profile ...
rank:2, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:2, trace log has been written to txt...
rank:2, finish release GPU memory ...
rank:2, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcfe6000000 recvbuff 0x7fcfe6000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcfe6000000,7fcfe6000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 3, finish warm up ...
rank_id = 3, input_tensor_shapes: []
rank:3,cuda fwd time: 113.84627532958984
rank:3, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.31,timestamp=4409478929.68,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.71,timestamp=4409478936.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409478941.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.17,timestamp=4409478947.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409478952.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.04,timestamp=4409478958.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409478963.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.0,timestamp=4409478969.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409478974.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409478980.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409478985.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409478992.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409478996.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409479003.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409479007.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409479014.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409479019.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409479025.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.52,timestamp=4409479030.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.92,timestamp=4409479037.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.37,timestamp=4409479041.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 3, finish FWD profile ...
rank:3, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.91,timestamp=4409479050.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.22,timestamp=4409479064.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409479073.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409479087.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409479096.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409479110.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409479119.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409479133.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409479142.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409479155.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409479164.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409479178.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409479187.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409479200.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409479209.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409479223.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409479232.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409479246.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409479255.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.2,timestamp=4409479269.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:3, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:3,optimizer_step time: 29.75641632080078
rank:3, finish optimizer.step profile ...
rank:3, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:3, trace log has been written to txt...
rank:3, finish release GPU memory ...
rank:3, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff400 recvbuff 0x7fcff27ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff400,7fcff27ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd27e000000 recvbuff 0x7fd27e000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd27e000000,7fd27e000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 4, finish warm up ...
rank_id = 4, input_tensor_shapes: []
rank:4,cuda fwd time: 120.22681427001953
rank:4, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.29,timestamp=4409480283.34,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.45,timestamp=4409480290.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409480295.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.04,timestamp=4409480301.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409480305.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409480312.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409480316.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.98,timestamp=4409480328.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.1,timestamp=4409480333.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.18,timestamp=4409480341.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.63,timestamp=4409480345.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409480352.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409480356.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409480363.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409480368.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409480374.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.58,timestamp=4409480379.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409480386.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.53,timestamp=4409480390.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.94,timestamp=4409480397.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.36,timestamp=4409480402.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 4, finish FWD profile ...
rank:4, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.84,timestamp=4409480410.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.14,timestamp=4409480424.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409480433.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409480447.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409480456.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409480469.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409480478.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409480492.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409480501.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409480514.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409480523.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409480537.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409480546.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409480559.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409480568.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409480582.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409480591.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.12,timestamp=4409480605.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.61,timestamp=4409480614.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409480628.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:4, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:4,optimizer_step time: 29.55776023864746
rank:4, finish optimizer.step profile ...
rank:4, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:4, trace log has been written to txt...
rank:4, finish release GPU memory ...
rank:4, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcfe6000000 recvbuff 0x7fcfe6000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcfe6000000,7fcfe6000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 5, finish warm up ...
rank_id = 5, input_tensor_shapes: []
rank:5,cuda fwd time: 116.73702239990234
rank:5, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409481640.27,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.57,timestamp=4409481647.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409481651.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.08,timestamp=4409481658.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409481662.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.06,timestamp=4409481669.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409481673.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409481679.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409481684.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409481691.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409481695.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.9,timestamp=4409481704.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.41,timestamp=4409481709.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.83,timestamp=4409481717.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.62,timestamp=4409481721.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409481728.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409481733.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409481739.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.53,timestamp=4409481744.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.98,timestamp=4409481750.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409481755.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 5, finish FWD profile ...
rank:5, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.9,timestamp=4409481763.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.25,timestamp=4409481777.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409481786.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409481800.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409481809.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409481824.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409481833.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.99,timestamp=4409481846.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409481855.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409481869.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409481878.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409481892.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409481900.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409481914.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409481923.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409481937.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409481946.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409481960.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409481969.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409481983.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:5, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:5,optimizer_step time: 29.681663513183594
rank:5, finish optimizer.step profile ...
rank:5, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:5, trace log has been written to txt...
rank:5, finish release GPU memory ...
rank:5, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff400 recvbuff 0x7fcff27ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff400,7fcff27ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd27e000000 recvbuff 0x7fd27e000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd27e000000,7fd27e000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 6, finish warm up ...
rank_id = 6, input_tensor_shapes: []
rank:6,cuda fwd time: 113.38956451416016
rank:6, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409482990.05,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.52,timestamp=4409482996.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409483001.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409483007.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409483012.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.06,timestamp=4409483018.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409483023.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409483029.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409483034.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409483040.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409483045.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409483052.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409483056.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409483063.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409483068.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409483074.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409483079.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409483085.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.57,timestamp=4409483090.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.04,timestamp=4409483097.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.42,timestamp=4409483102.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 6, finish FWD profile ...
rank:6, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.91,timestamp=4409483110.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.18,timestamp=4409483124.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409483133.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409483146.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409483155.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409483169.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409483178.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409483191.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409483200.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409483214.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409483224.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409483238.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409483247.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409483261.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409483270.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409483284.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409483293.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409483306.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409483315.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409483329.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:6, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:6,optimizer_step time: 29.648895263671875
rank:6, finish optimizer.step profile ...
rank:6, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:6, trace log has been written to txt...
rank:6, finish release GPU memory ...
rank:6, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcfe6000000 recvbuff 0x7fcfe6000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcfe6000000,7fcfe6000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 0): 1075484672
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1075484672 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 7, finish warm up ...
rank_id = 7, input_tensor_shapes: []
rank:7,cuda fwd time: 113.00249481201172
rank:7, fwd_subop num: 21, fwd_subop: ['trace_src_func=_reduce,duration=0.31,timestamp=4409484292.85,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.72,timestamp=4409484299.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409484304.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.19,timestamp=4409484310.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.13,timestamp=4409484315.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.21,timestamp=4409484321.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409484326.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409484332.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409484337.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409484343.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409484348.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.37,timestamp=4409484354.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409484359.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.38,timestamp=4409484366.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409484370.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409484377.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409484382.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409484388.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.68,timestamp=4409484393.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.52,timestamp=4409484399.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.48,timestamp=4409484404.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 7, finish FWD profile ...
rank:7, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.85,timestamp=4409484412.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=10.9,timestamp=4409484426.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409484435.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409484449.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409484458.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.23,timestamp=4409484472.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409484481.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.13,timestamp=4409484495.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409484504.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409484518.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409484527.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409484541.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409484550.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409484564.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409484572.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409484586.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409484595.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409484609.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409484618.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409484632.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:7, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:7,optimizer_step time: 29.54854393005371
rank:7, finish optimizer.step profile ...
rank:7, Before memory release - Allocated: 25971280384, Reserved: 41114664960
rank:7, trace log has been written to txt...
rank:7, finish release GPU memory ...
rank:7, After memory release - Allocated: 8629306368, Reserved: 17286823936
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff400 recvbuff 0x7fcff27ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff400,7fcff27ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 8, finish warm up ...
rank_id = 8, input_tensor_shapes: [(2048, 2, 8192)]
rank:8,cuda fwd time: 111.60063934326172
rank:8, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409485871.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409485876.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409485882.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409485886.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.01,timestamp=4409485893.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409485897.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409485903.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409485908.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409485915.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409485919.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409485926.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409485931.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409485937.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409485942.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409485948.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409485953.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409485960.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409485964.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409485971.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409485976.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 8, finish FWD profile ...
rank:8, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.81,timestamp=4409485984.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.02,timestamp=4409485998.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409486007.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409486020.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409486029.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.9,timestamp=4409486043.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409486052.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409486066.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409486074.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409486088.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409486097.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409486111.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409486120.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409486134.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409486143.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409486157.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409486166.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409486180.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409486189.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409486203.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:8, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:8,optimizer_step time: 27.862016677856445
rank:8, finish optimizer.step profile ...
rank:8, Before memory release - Allocated: 25147099648, Reserved: 39940259840
rank:8, trace log has been written to txt...
rank:8, finish release GPU memory ...
rank:8, After memory release - Allocated: 16955311104, Reserved: 17414750208
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 9, finish warm up ...
rank_id = 9, input_tensor_shapes: [(2048, 2, 8192)]
rank:9,cuda fwd time: 120.06195068359375
rank:9, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409487391.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409487395.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409487401.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409487406.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409487412.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409487417.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409487423.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409487428.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409487434.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409487439.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409487454.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409487459.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409487465.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409487470.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409487476.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409487481.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409487488.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409487492.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409487499.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.65,timestamp=4409487503.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 9, finish FWD profile ...
rank:9, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.79,timestamp=4409487512.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.5,timestamp=4409487526.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409487535.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409487549.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409487558.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409487572.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409487581.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409487595.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409487604.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409487618.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409487627.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409487641.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409487650.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409487664.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409487673.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409487687.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409487696.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.99,timestamp=4409487710.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.53,timestamp=4409487719.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409487733.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:9, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:9,optimizer_step time: 27.74425506591797
rank:9, finish optimizer.step profile ...
rank:9, Before memory release - Allocated: 33473104384, Reserved: 48463085568
rank:9, trace log has been written to txt...
rank:9, finish release GPU memory ...
rank:9, After memory release - Allocated: 16955311104, Reserved: 25474105344
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff400 recvbuff 0x7fcff27ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff400,7fcff27ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 10, finish warm up ...
rank_id = 10, input_tensor_shapes: [(2048, 2, 8192)]
rank:10,cuda fwd time: 112.60415649414062
rank:10, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.49,timestamp=4409488957.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409488961.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.96,timestamp=4409488967.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409488972.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409488978.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409488983.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409488989.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.7,timestamp=4409488994.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409489000.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409489005.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409489012.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409489016.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409489023.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409489028.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409489034.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409489039.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409489046.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409489050.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409489057.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409489062.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 10, finish FWD profile ...
rank:10, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.42,timestamp=4409489072.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.36,timestamp=4409489085.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409489094.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409489108.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409489117.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409489131.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409489140.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409489154.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409489163.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409489177.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409489186.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409489200.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409489209.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409489222.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409489231.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409489245.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409489254.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409489267.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409489276.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409489290.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:10, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:10,optimizer_step time: 27.854848861694336
rank:10, finish optimizer.step profile ...
rank:10, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:10, trace log has been written to txt...
rank:10, finish release GPU memory ...
rank:10, After memory release - Allocated: 16955311104, Reserved: 25474105344
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffc00 recvbuff 0x7fcff27ffc00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffc00,7fcff27ffc00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffe00 recvbuff 0x7fcff27ffe00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffe00,7fcff27ffe00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 11, finish warm up ...
rank_id = 11, input_tensor_shapes: [(2048, 2, 8192)]
rank:11,cuda fwd time: 118.28121948242188
rank:11, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409490525.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409490530.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409490536.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409490541.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409490547.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409490552.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409490558.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.73,timestamp=4409490562.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409490569.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.01,timestamp=4409490574.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.08,timestamp=4409490584.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.66,timestamp=4409490588.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.87,timestamp=4409490596.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.01,timestamp=4409490601.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.96,timestamp=4409490610.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.09,timestamp=4409490614.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409490621.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409490625.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409490632.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409490637.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 11, finish FWD profile ...
rank:11, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.73,timestamp=4409490645.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.99,timestamp=4409490658.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.14,timestamp=4409490667.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409490681.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409490690.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409490703.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409490712.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.89,timestamp=4409490726.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409490735.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409490749.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409490758.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409490772.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409490781.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409490795.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409490804.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409490818.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409490827.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409490841.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409490850.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409490863.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:11, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:11,optimizer_step time: 28.53376007080078
rank:11, finish optimizer.step profile ...
rank:11, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:11, trace log has been written to txt...
rank:11, finish release GPU memory ...
rank:11, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 12, finish warm up ...
rank_id = 12, input_tensor_shapes: [(2048, 2, 8192)]
rank:12,cuda fwd time: 121.37779235839844
rank:12, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.54,timestamp=4409492032.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409492036.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409492042.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409492047.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409492053.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409492058.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409492064.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409492069.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409492075.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409492080.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409492086.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409492091.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409492108.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409492113.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.19,timestamp=4409492119.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409492124.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409492130.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409492135.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409492141.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409492146.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 12, finish FWD profile ...
rank:12, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.79,timestamp=4409492155.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.22,timestamp=4409492168.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409492178.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409492192.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409492201.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409492215.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409492224.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409492237.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409492246.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409492260.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409492269.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409492283.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409492291.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409492305.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409492314.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409492328.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409492337.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409492351.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409492360.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409492374.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:12, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:12,optimizer_step time: 27.77395248413086
rank:12, finish optimizer.step profile ...
rank:12, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:12, trace log has been written to txt...
rank:12, finish release GPU memory ...
rank:12, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff600 recvbuff 0x7fcff27ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff600,7fcff27ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffa00 recvbuff 0x7fcff27ffa00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffa00,7fcff27ffa00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 13, finish warm up ...
rank_id = 13, input_tensor_shapes: [(2048, 2, 8192)]
rank:13,cuda fwd time: 122.97830200195312
rank:13, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409493644.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409493649.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409493655.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409493659.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409493666.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409493670.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409493676.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409493681.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409493687.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.51,timestamp=4409493692.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.04,timestamp=4409493699.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.71,timestamp=4409493704.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409493713.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.99,timestamp=4409493726.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409493733.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409493738.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409493744.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409493749.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409493755.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409493760.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 13, finish FWD profile ...
rank:13, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.73,timestamp=4409493768.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.92,timestamp=4409493782.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.21,timestamp=4409493790.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409493804.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409493813.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409493827.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409493836.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409493850.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409493859.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409493873.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409493882.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409493897.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.61,timestamp=4409493906.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409493920.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409493929.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409493943.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409493951.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409493965.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409493974.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409493988.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:13, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff200 recvbuff 0x7fcff27ff200 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff200,7fcff27ff200,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:13,optimizer_step time: 27.925504684448242
rank:13, finish optimizer.step profile ...
rank:13, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:13, trace log has been written to txt...
rank:13, finish release GPU memory ...
rank:13, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffc00 recvbuff 0x7fcff27ffc00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffc00,7fcff27ffc00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ffe00 recvbuff 0x7fcff27ffe00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ffe00,7fcff27ffe00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff000 recvbuff 0x7fcff27ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff000,7fcff27ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 14, finish warm up ...
rank_id = 14, input_tensor_shapes: [(2048, 2, 8192)]
rank:14,cuda fwd time: 112.75878143310547
rank:14, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.49,timestamp=4409495229.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409495234.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.96,timestamp=4409495240.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409495244.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.01,timestamp=4409495251.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409495255.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409495261.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409495266.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409495273.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409495277.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.03,timestamp=4409495285.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409495290.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409495296.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409495301.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409495307.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409495312.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409495319.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409495323.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409495330.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409495335.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 14, finish FWD profile ...
rank:14, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.86,timestamp=4409495343.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.13,timestamp=4409495357.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409495366.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409495380.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409495388.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409495402.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409495411.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409495425.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409495434.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409495448.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409495458.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409495472.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409495481.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409495494.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409495503.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409495517.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409495526.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.74,timestamp=4409495539.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409495548.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409495562.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:14, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcff27ff800 recvbuff 0x7fcff27ff800 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcff27ff800,7fcff27ff800,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:14,optimizer_step time: 27.685888290405273
rank:14, finish optimizer.step profile ...
rank:14, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:14, trace log has been written to txt...
rank:14, finish release GPU memory ...
rank:14, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 1): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 15, finish warm up ...
rank_id = 15, input_tensor_shapes: [(2048, 2, 8192)]
rank:15,cuda fwd time: 111.41222381591797
rank:15, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409496725.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409496729.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409496735.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409496740.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.15,timestamp=4409496746.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409496751.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409496757.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409496762.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409496768.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409496773.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409496779.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409496784.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.2,timestamp=4409496791.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409496796.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.22,timestamp=4409496802.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409496807.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409496813.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409496818.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409496824.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409496829.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 15, finish FWD profile ...
rank:15, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.84,timestamp=4409496838.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.07,timestamp=4409496851.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409496860.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409496874.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409496883.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409496897.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409496906.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409496919.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409496928.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409496942.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409496951.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409496965.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.51,timestamp=4409496974.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409496988.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409496997.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.01,timestamp=4409497011.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409497020.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409497034.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409497042.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409497056.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:15, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:15,optimizer_step time: 27.73708724975586
rank:15, finish optimizer.step profile ...
rank:15, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:15, trace log has been written to txt...
rank:15, finish release GPU memory ...
rank:15, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 16, finish warm up ...
rank_id = 16, input_tensor_shapes: [(2048, 2, 8192)]
rank:16,cuda fwd time: 111.26374053955078
rank:16, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.61,timestamp=4409498412.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409498417.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409498423.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409498428.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.15,timestamp=4409498434.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409498439.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409498445.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409498449.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409498456.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409498460.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409498467.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409498472.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409498478.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409498483.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409498489.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409498494.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.29,timestamp=4409498501.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409498506.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.29,timestamp=4409498512.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409498517.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 16, finish FWD profile ...
rank:16, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409498525.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.16,timestamp=4409498539.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409498548.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.01,timestamp=4409498562.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409498571.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409498585.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409498594.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409498608.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409498617.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409498631.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409498640.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409498654.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409498662.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409498676.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409498685.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409498699.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409498707.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409498721.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409498730.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409498744.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:16, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:16,optimizer_step time: 27.69715118408203
rank:16, finish optimizer.step profile ...
rank:16, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:16, trace log has been written to txt...
rank:16, finish release GPU memory ...
rank:16, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 17, finish warm up ...
rank_id = 17, input_tensor_shapes: [(2048, 2, 8192)]
rank:17,cuda fwd time: 112.09420776367188
rank:17, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409499979.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409499984.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409499990.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409499995.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.02,timestamp=4409500001.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409500006.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409500012.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409500017.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409500023.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409500028.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409500034.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409500039.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409500046.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409500050.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409500057.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409500062.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409500068.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409500073.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409500080.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409500085.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 17, finish FWD profile ...
rank:17, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.85,timestamp=4409500093.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.1,timestamp=4409500107.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409500116.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409500130.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409500139.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409500152.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409500161.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409500175.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409500184.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409500198.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409500207.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.21,timestamp=4409500221.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409500230.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409500244.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409500253.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409500267.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409500276.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409500290.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409500299.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409500313.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:17, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:17,optimizer_step time: 27.806720733642578
rank:17, finish optimizer.step profile ...
rank:17, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:17, trace log has been written to txt...
rank:17, finish release GPU memory ...
rank:17, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 18, finish warm up ...
rank_id = 18, input_tensor_shapes: [(2048, 2, 8192)]
rank:18,cuda fwd time: 119.7127685546875
rank:18, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409501551.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409501556.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409501562.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409501567.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409501573.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409501578.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409501584.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409501588.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409501595.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.99,timestamp=4409501603.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409501610.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409501615.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409501621.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409501626.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409501632.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409501637.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409501643.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409501648.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.07,timestamp=4409501659.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409501664.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 18, finish FWD profile ...
rank:18, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409501672.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.09,timestamp=4409501686.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.84,timestamp=4409501695.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.63,timestamp=4409501709.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409501717.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409501731.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409501740.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409501753.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409501762.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409501776.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409501785.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409501798.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409501807.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409501821.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409501830.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409501844.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409501853.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409501867.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409501876.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409501890.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:18, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:18,optimizer_step time: 27.72991943359375
rank:18, finish optimizer.step profile ...
rank:18, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:18, trace log has been written to txt...
rank:18, finish release GPU memory ...
rank:18, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 19, finish warm up ...
rank_id = 19, input_tensor_shapes: [(2048, 2, 8192)]
rank:19,cuda fwd time: 112.19660949707031
rank:19, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409503049.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409503053.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409503060.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409503064.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409503070.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409503075.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409503081.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409503086.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.16,timestamp=4409503092.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409503097.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409503104.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409503108.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409503115.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409503120.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.99,timestamp=4409503127.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409503132.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409503138.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409503143.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.26,timestamp=4409503149.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409503154.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 19, finish FWD profile ...
rank:19, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409503163.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.11,timestamp=4409503177.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409503185.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409503199.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409503208.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409503222.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409503231.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409503245.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409503254.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409503268.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409503277.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409503291.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409503300.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409503314.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409503323.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409503336.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409503345.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409503359.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409503368.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409503382.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:19, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:19,optimizer_step time: 27.854848861694336
rank:19, finish optimizer.step profile ...
rank:19, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:19, trace log has been written to txt...
rank:19, finish release GPU memory ...
rank:19, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 20, finish warm up ...
rank_id = 20, input_tensor_shapes: [(2048, 2, 8192)]
rank:20,cuda fwd time: 111.48390197753906
rank:20, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409504524.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409504528.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409504535.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409504539.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.16,timestamp=4409504545.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409504550.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409504556.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409504561.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409504567.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409504572.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.34,timestamp=4409504578.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409504583.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409504590.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409504594.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409504601.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409504606.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409504612.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409504617.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409504623.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409504628.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 20, finish FWD profile ...
rank:20, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.77,timestamp=4409504637.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.0,timestamp=4409504650.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.18,timestamp=4409504659.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.23,timestamp=4409504673.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409504682.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409504696.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.64,timestamp=4409504705.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.19,timestamp=4409504719.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409504729.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409504743.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409504752.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409504765.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409504774.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409504788.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409504797.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409504810.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409504819.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.71,timestamp=4409504833.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409504842.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409504856.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:20, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:20,optimizer_step time: 27.777023315429688
rank:20, finish optimizer.step profile ...
rank:20, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:20, trace log has been written to txt...
rank:20, finish release GPU memory ...
rank:20, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 21, finish warm up ...
rank_id = 21, input_tensor_shapes: [(2048, 2, 8192)]
rank:21,cuda fwd time: 120.52275085449219
rank:21, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.65,timestamp=4409506007.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409506012.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409506018.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409506022.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409506029.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409506033.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409506039.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409506044.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409506057.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409506062.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.19,timestamp=4409506069.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409506073.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409506080.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.01,timestamp=4409506087.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409506094.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409506098.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409506105.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409506109.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.16,timestamp=4409506116.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409506121.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 21, finish FWD profile ...
rank:21, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.81,timestamp=4409506129.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.02,timestamp=4409506143.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.95,timestamp=4409506152.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409506165.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409506174.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409506188.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409506197.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409506210.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409506219.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409506233.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409506242.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409506256.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409506265.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409506279.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409506288.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409506302.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409506311.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409506325.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409506334.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409506348.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:21, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:21,optimizer_step time: 27.77395248413086
rank:21, finish optimizer.step profile ...
rank:21, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:21, trace log has been written to txt...
rank:21, finish release GPU memory ...
rank:21, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 22, finish warm up ...
rank_id = 22, input_tensor_shapes: [(2048, 2, 8192)]
rank:22,cuda fwd time: 111.15007781982422
rank:22, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.47,timestamp=4409507556.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409507560.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.04,timestamp=4409507566.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409507571.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.08,timestamp=4409507577.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409507582.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.22,timestamp=4409507588.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409507593.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409507599.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409507604.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409507610.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409507615.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.22,timestamp=4409507621.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409507626.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.15,timestamp=4409507632.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409507637.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409507644.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409507648.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409507655.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409507660.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 22, finish FWD profile ...
rank:22, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.94,timestamp=4409507668.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.25,timestamp=4409507682.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409507691.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409507705.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409507714.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409507727.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409507736.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409507750.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409507759.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409507773.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409507783.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.12,timestamp=4409507797.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409507806.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409507820.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409507829.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.43,timestamp=4409507843.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409507852.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409507866.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409507875.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409507889.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:22, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:22,optimizer_step time: 27.633663177490234
rank:22, finish optimizer.step profile ...
rank:22, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:22, trace log has been written to txt...
rank:22, finish release GPU memory ...
rank:22, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 2): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 23, finish warm up ...
rank_id = 23, input_tensor_shapes: [(2048, 2, 8192)]
rank:23,cuda fwd time: 125.00582122802734
rank:23, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409509047.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409509052.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409509058.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409509063.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409509069.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409509074.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.88,timestamp=4409509089.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.41,timestamp=4409509094.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409509100.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409509105.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.15,timestamp=4409509117.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409509121.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409509128.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409509132.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409509139.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409509143.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409509150.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409509155.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409509161.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409509166.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 23, finish FWD profile ...
rank:23, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=4.41,timestamp=4409509175.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=10.68,timestamp=4409509189.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409509198.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.13,timestamp=4409509212.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409509221.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409509235.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409509244.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409509258.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409509267.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409509281.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409509290.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409509304.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409509312.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409509326.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409509335.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409509349.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409509358.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409509372.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409509381.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409509395.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:23, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:23,optimizer_step time: 27.757568359375
rank:23, finish optimizer.step profile ...
rank:23, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:23, trace log has been written to txt...
rank:23, finish release GPU memory ...
rank:23, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 24, finish warm up ...
rank_id = 24, input_tensor_shapes: [(2048, 2, 8192)]
rank:24,cuda fwd time: 113.46227264404297
rank:24, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409510538.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409510543.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409510549.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409510554.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409510560.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409510564.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.04,timestamp=4409510571.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.99,timestamp=4409510576.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.76,timestamp=4409510584.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409510589.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409510595.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409510600.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409510606.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409510611.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409510617.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409510622.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.35,timestamp=4409510629.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409510633.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409510640.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409510645.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 24, finish FWD profile ...
rank:24, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.93,timestamp=4409510653.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.28,timestamp=4409510667.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409510676.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409510690.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409510699.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.01,timestamp=4409510713.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409510722.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409510736.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409510745.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.89,timestamp=4409510759.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409510768.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409510781.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409510790.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409510804.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409510813.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409510827.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.73,timestamp=4409510836.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409510850.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409510859.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.14,timestamp=4409510873.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:24, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:24,optimizer_step time: 27.823104858398438
rank:24, finish optimizer.step profile ...
rank:24, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:24, trace log has been written to txt...
rank:24, finish release GPU memory ...
rank:24, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 25, finish warm up ...
rank_id = 25, input_tensor_shapes: [(2048, 2, 8192)]
rank:25,cuda fwd time: 115.91168212890625
rank:25, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409512098.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409512103.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409512109.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409512114.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409512120.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409512125.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409512131.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409512135.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409512142.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409512147.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409512153.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409512158.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.07,timestamp=4409512168.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409512173.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409512179.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409512184.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409512190.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409512195.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409512202.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409512206.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 25, finish FWD profile ...
rank:25, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.79,timestamp=4409512215.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.13,timestamp=4409512229.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409512238.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409512252.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409512261.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409512275.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409512284.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409512297.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409512306.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409512320.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409512329.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.64,timestamp=4409512343.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.2,timestamp=4409512352.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.67,timestamp=4409512365.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409512374.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409512388.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409512397.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.14,timestamp=4409512412.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409512421.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.14,timestamp=4409512435.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:25, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:25,optimizer_step time: 28.79078483581543
rank:25, finish optimizer.step profile ...
rank:25, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:25, trace log has been written to txt...
rank:25, finish release GPU memory ...
rank:25, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 26, finish warm up ...
rank_id = 26, input_tensor_shapes: [(2048, 2, 8192)]
rank:26,cuda fwd time: 121.99935913085938
rank:26, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409513669.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409513674.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409513680.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409513685.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409513691.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409513696.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409513702.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.53,timestamp=4409513707.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409513713.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409513718.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409513724.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409513729.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.98,timestamp=4409513746.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409513751.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409513757.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409513762.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.73,timestamp=4409513769.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409513773.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409513780.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409513785.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 26, finish FWD profile ...
rank:26, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.76,timestamp=4409513793.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.27,timestamp=4409513807.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409513816.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409513830.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409513839.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409513853.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409513862.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.35,timestamp=4409513875.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409513884.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.71,timestamp=4409513898.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409513907.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409513920.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409513929.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409513943.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409513952.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409513965.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409513975.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409513989.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409513998.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409514012.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:26, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:26,optimizer_step time: 27.830272674560547
rank:26, finish optimizer.step profile ...
rank:26, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:26, trace log has been written to txt...
rank:26, finish release GPU memory ...
rank:26, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 27, finish warm up ...
rank_id = 27, input_tensor_shapes: [(2048, 2, 8192)]
rank:27,cuda fwd time: 111.02003479003906
rank:27, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.61,timestamp=4409515196.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409515200.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.04,timestamp=4409515207.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409515211.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409515217.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409515222.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409515228.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409515233.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.97,timestamp=4409515240.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.46,timestamp=4409515244.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409515251.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409515255.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409515262.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409515266.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409515273.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409515278.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.24,timestamp=4409515284.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409515289.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.16,timestamp=4409515295.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409515300.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 27, finish FWD profile ...
rank:27, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.93,timestamp=4409515308.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.25,timestamp=4409515322.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409515331.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409515345.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409515354.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.01,timestamp=4409515368.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409515377.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409515391.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409515400.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409515414.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409515423.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409515437.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409515446.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409515459.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409515468.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409515482.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409515491.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409515505.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.64,timestamp=4409515514.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.19,timestamp=4409515528.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:27, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:27,optimizer_step time: 27.7073917388916
rank:27, finish optimizer.step profile ...
rank:27, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:27, trace log has been written to txt...
rank:27, finish release GPU memory ...
rank:27, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 28, finish warm up ...
rank_id = 28, input_tensor_shapes: [(2048, 2, 8192)]
rank:28,cuda fwd time: 114.45145416259766
rank:28, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.5,timestamp=4409516760.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409516765.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409516771.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409516776.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409516782.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409516787.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.98,timestamp=4409516796.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409516800.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409516807.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409516812.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409516818.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409516823.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409516829.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409516834.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409516840.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409516845.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409516852.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409516857.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409516863.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409516868.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 28, finish FWD profile ...
rank:28, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.86,timestamp=4409516876.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.13,timestamp=4409516890.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409516899.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409516913.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409516922.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409516935.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409516944.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.74,timestamp=4409516958.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409516966.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409516980.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409516989.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409517003.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409517012.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409517026.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409517035.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409517049.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409517058.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409517072.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.51,timestamp=4409517081.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409517095.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:28, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:28,optimizer_step time: 27.801599502563477
rank:28, finish optimizer.step profile ...
rank:28, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:28, trace log has been written to txt...
rank:28, finish release GPU memory ...
rank:28, After memory release - Allocated: 16955311104, Reserved: 25876758528
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 29, finish warm up ...
rank_id = 29, input_tensor_shapes: [(2048, 2, 8192)]
rank:29,cuda fwd time: 113.05574035644531
rank:29, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.66,timestamp=4409518257.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409518262.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409518268.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409518273.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409518279.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409518283.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.58,timestamp=4409518289.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409518294.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409518302.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409518307.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409518313.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409518318.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409518324.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409518329.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409518335.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409518340.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409518347.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409518351.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409518359.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.52,timestamp=4409518364.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 29, finish FWD profile ...
rank:29, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409518372.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.14,timestamp=4409518385.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409518394.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.9,timestamp=4409518408.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409518417.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.53,timestamp=4409518431.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409518440.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409518454.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409518463.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409518477.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409518486.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.67,timestamp=4409518499.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409518508.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409518522.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409518531.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409518545.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.69,timestamp=4409518554.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.29,timestamp=4409518568.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.67,timestamp=4409518577.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.29,timestamp=4409518591.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:29, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:29,optimizer_step time: 27.800575256347656
rank:29, finish optimizer.step profile ...
rank:29, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:29, trace log has been written to txt...
rank:29, finish release GPU memory ...
rank:29, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 30, finish warm up ...
rank_id = 30, input_tensor_shapes: [(2048, 2, 8192)]
rank:30,cuda fwd time: 122.41203308105469
rank:30, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409519754.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409519759.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409519765.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409519769.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409519776.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409519780.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409519786.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.99,timestamp=4409519793.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409519799.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409519804.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.94,timestamp=4409519820.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409519824.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.26,timestamp=4409519831.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.47,timestamp=4409519836.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.14,timestamp=4409519842.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.41,timestamp=4409519847.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409519854.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409519858.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.16,timestamp=4409519865.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409519870.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 30, finish FWD profile ...
rank:30, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.76,timestamp=4409519878.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.02,timestamp=4409519891.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409519900.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.08,timestamp=4409519914.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.18,timestamp=4409519923.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409519936.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409519945.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409519959.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409519968.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409519982.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409519991.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409520005.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409520014.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409520027.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409520036.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409520050.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409520060.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409520073.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409520082.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409520096.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:30, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:30,optimizer_step time: 27.7708797454834
rank:30, finish optimizer.step profile ...
rank:30, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:30, trace log has been written to txt...
rank:30, finish release GPU memory ...
rank:30, After memory release - Allocated: 16955311104, Reserved: 25876758528
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 3): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 31, finish warm up ...
rank_id = 31, input_tensor_shapes: [(2048, 2, 8192)]
rank:31,cuda fwd time: 121.88671875
rank:31, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.56,timestamp=4409521249.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409521254.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.02,timestamp=4409521260.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409521265.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409521271.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409521276.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409521282.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409521286.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.15,timestamp=4409521293.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.56,timestamp=4409521297.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.91,timestamp=4409521305.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409521309.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.26,timestamp=4409521316.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409521321.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409521327.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409521332.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.03,timestamp=4409521340.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.46,timestamp=4409521345.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.43,timestamp=4409521354.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.34,timestamp=4409521364.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 31, finish FWD profile ...
rank:31, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=2.08,timestamp=4409521375.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.58,timestamp=4409521405.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409521414.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409521427.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409521436.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409521450.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409521459.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.89,timestamp=4409521473.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409521482.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409521495.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409521504.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.74,timestamp=4409521518.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409521527.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409521540.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409521549.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.99,timestamp=4409521563.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409521572.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409521586.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409521595.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.57,timestamp=4409521610.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:31, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:31,optimizer_step time: 27.72889518737793
rank:31, finish optimizer.step profile ...
rank:31, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:31, trace log has been written to txt...
rank:31, finish release GPU memory ...
rank:31, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 32, finish warm up ...
rank_id = 32, input_tensor_shapes: [(2048, 2, 8192)]
rank:32,cuda fwd time: 119.1915512084961
rank:32, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.66,timestamp=4409522779.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409522784.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409522790.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409522794.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409522801.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409522805.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409522811.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409522816.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409522822.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409522827.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409522833.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409522838.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409522844.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409522849.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409522855.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409522860.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409522875.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409522880.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.19,timestamp=4409522887.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409522891.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 32, finish FWD profile ...
rank:32, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.78,timestamp=4409522900.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.0,timestamp=4409522914.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409522922.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.69,timestamp=4409522936.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409522945.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409522958.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409522967.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409522981.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409522990.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409523004.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409523014.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409523028.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.53,timestamp=4409523037.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.12,timestamp=4409523051.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409523060.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409523074.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409523083.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409523097.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409523106.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409523119.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:32, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:32,optimizer_step time: 27.676671981811523
rank:32, finish optimizer.step profile ...
rank:32, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:32, trace log has been written to txt...
rank:32, finish release GPU memory ...
rank:32, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 33, finish warm up ...
rank_id = 33, input_tensor_shapes: [(2048, 2, 8192)]
rank:33,cuda fwd time: 111.50950622558594
rank:33, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.62,timestamp=4409524302.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409524306.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409524313.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409524317.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409524323.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409524328.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409524334.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409524339.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.26,timestamp=4409524345.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409524350.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409524356.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409524361.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.39,timestamp=4409524368.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409524372.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.43,timestamp=4409524379.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409524384.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.4,timestamp=4409524390.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409524395.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409524402.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409524406.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 33, finish FWD profile ...
rank:33, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409524415.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.23,timestamp=4409524429.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409524438.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409524452.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409524461.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409524474.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409524484.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409524497.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409524506.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409524520.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409524529.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409524542.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409524551.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409524565.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409524574.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409524588.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409524597.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409524611.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409524620.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409524634.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:33, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:33,optimizer_step time: 27.692031860351562
rank:33, finish optimizer.step profile ...
rank:33, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:33, trace log has been written to txt...
rank:33, finish release GPU memory ...
rank:33, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 34, finish warm up ...
rank_id = 34, input_tensor_shapes: [(2048, 2, 8192)]
rank:34,cuda fwd time: 114.70745849609375
rank:34, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.62,timestamp=4409525790.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409525795.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409525801.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409525806.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409525812.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409525817.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409525823.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409525827.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.11,timestamp=4409525838.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409525843.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409525849.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409525854.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409525860.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409525865.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409525871.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409525876.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409525882.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409525887.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409525894.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409525898.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 34, finish FWD profile ...
rank:34, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.81,timestamp=4409525906.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.03,timestamp=4409525920.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409525929.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409525943.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409525952.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409525966.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409525975.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.19,timestamp=4409525989.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409525998.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409526012.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409526021.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409526035.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409526044.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409526058.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409526067.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409526081.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409526089.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409526103.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409526112.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409526126.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:34, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:34,optimizer_step time: 27.702272415161133
rank:34, finish optimizer.step profile ...
rank:34, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:34, trace log has been written to txt...
rank:34, finish release GPU memory ...
rank:34, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 35, finish warm up ...
rank_id = 35, input_tensor_shapes: [(2048, 2, 8192)]
rank:35,cuda fwd time: 111.48697662353516
rank:35, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.6,timestamp=4409527296.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409527301.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409527307.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409527312.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.15,timestamp=4409527318.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409527322.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409527328.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409527333.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409527340.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409527344.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409527351.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.66,timestamp=4409527355.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.91,timestamp=4409527362.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409527367.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409527373.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409527378.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409527385.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409527389.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409527396.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409527401.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 35, finish FWD profile ...
rank:35, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.93,timestamp=4409527409.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.22,timestamp=4409527423.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409527432.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409527446.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409527455.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409527468.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.51,timestamp=4409527478.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409527492.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.53,timestamp=4409527501.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.13,timestamp=4409527515.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409527524.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409527538.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409527547.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409527561.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409527570.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409527584.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409527593.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409527607.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409527615.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409527629.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:35, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:35,optimizer_step time: 27.670528411865234
rank:35, finish optimizer.step profile ...
rank:35, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:35, trace log has been written to txt...
rank:35, finish release GPU memory ...
rank:35, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 36, finish warm up ...
rank_id = 36, input_tensor_shapes: [(2048, 2, 8192)]
rank:36,cuda fwd time: 121.12588500976562
rank:36, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.4,timestamp=4409528849.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409528854.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409528860.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409528864.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409528871.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409528875.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409528881.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409528886.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409528892.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409528897.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.16,timestamp=4409528903.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409528908.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409528914.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409528919.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409528925.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409528930.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409528936.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409528941.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409528958.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409528963.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 36, finish FWD profile ...
rank:36, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.75,timestamp=4409528971.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.88,timestamp=4409528985.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.16,timestamp=4409528994.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409529007.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409529016.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.24,timestamp=4409529030.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409529039.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409529053.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409529062.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409529076.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409529085.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409529099.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409529108.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409529122.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409529131.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409529145.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409529155.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409529169.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409529178.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409529191.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:36, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:36,optimizer_step time: 28.15488052368164
rank:36, finish optimizer.step profile ...
rank:36, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:36, trace log has been written to txt...
rank:36, finish release GPU memory ...
rank:36, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 37, finish warm up ...
rank_id = 37, input_tensor_shapes: [(2048, 2, 8192)]
rank:37,cuda fwd time: 112.87654113769531
rank:37, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409530396.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409530400.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409530407.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409530411.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409530417.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409530422.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.34,timestamp=4409530428.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409530433.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.19,timestamp=4409530439.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409530444.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.3,timestamp=4409530451.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.55,timestamp=4409530456.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.38,timestamp=4409530462.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.63,timestamp=4409530467.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.29,timestamp=4409530474.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.63,timestamp=4409530479.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409530485.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.65,timestamp=4409530490.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.24,timestamp=4409530497.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.61,timestamp=4409530502.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 37, finish FWD profile ...
rank:37, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.55,timestamp=4409530510.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.48,timestamp=4409530524.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.12,timestamp=4409530533.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.67,timestamp=4409530547.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409530556.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409530569.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409530578.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.81,timestamp=4409530592.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409530601.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.87,timestamp=4409530615.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409530624.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409530637.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409530646.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409530660.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409530669.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409530683.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409530693.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409530707.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409530716.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409530730.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:37, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:37,optimizer_step time: 27.79033660888672
rank:37, finish optimizer.step profile ...
rank:37, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:37, trace log has been written to txt...
rank:37, finish release GPU memory ...
rank:37, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 38, finish warm up ...
rank_id = 38, input_tensor_shapes: [(2048, 2, 8192)]
rank:38,cuda fwd time: 115.78777313232422
rank:38, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.55,timestamp=4409531950.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409531955.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409531961.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409531965.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409531971.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409531976.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409531982.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409531987.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409531998.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409532003.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409532009.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409532014.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409532020.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409532025.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409532031.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409532036.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409532043.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409532047.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409532054.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409532059.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 38, finish FWD profile ...
rank:38, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.94,timestamp=4409532067.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.32,timestamp=4409532081.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409532090.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409532104.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409532113.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409532127.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409532136.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409532150.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409532159.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409532173.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409532182.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.53,timestamp=4409532196.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409532205.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409532219.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409532228.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409532242.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409532251.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.19,timestamp=4409532265.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409532275.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409532289.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:38, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:38,optimizer_step time: 27.787263870239258
rank:38, finish optimizer.step profile ...
rank:38, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:38, trace log has been written to txt...
rank:38, finish release GPU memory ...
rank:38, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 4): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 39, finish warm up ...
rank_id = 39, input_tensor_shapes: [(2048, 2, 8192)]
rank:39,cuda fwd time: 112.7925796508789
rank:39, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.34,timestamp=4409533503.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409533508.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409533514.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409533519.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409533525.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409533529.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409533536.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409533540.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409533547.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409533551.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409533558.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409533563.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409533569.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409533574.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409533580.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409533585.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409533592.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409533596.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409533603.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409533608.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 39, finish FWD profile ...
rank:39, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.62,timestamp=4409533617.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.23,timestamp=4409533631.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409533640.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409533654.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409533662.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409533676.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.96,timestamp=4409533685.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409533699.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409533708.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409533722.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409533731.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409533745.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409533754.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409533768.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409533778.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409533792.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409533801.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409533815.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409533824.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.96,timestamp=4409533838.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:39, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:39,optimizer_step time: 27.879423141479492
rank:39, finish optimizer.step profile ...
rank:39, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:39, trace log has been written to txt...
rank:39, finish release GPU memory ...
rank:39, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 40, finish warm up ...
rank_id = 40, input_tensor_shapes: [(2048, 2, 8192)]
rank:40,cuda fwd time: 111.10707092285156
rank:40, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409535045.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409535049.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409535056.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409535060.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409535066.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409535071.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409535077.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409535082.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409535088.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409535093.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.22,timestamp=4409535099.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409535104.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409535110.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409535115.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409535122.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409535126.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.29,timestamp=4409535133.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409535138.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409535144.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409535149.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 40, finish FWD profile ...
rank:40, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.62,timestamp=4409535157.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.16,timestamp=4409535171.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409535180.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409535194.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409535203.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409535217.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409535226.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409535240.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.51,timestamp=4409535249.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409535263.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409535272.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.23,timestamp=4409535286.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409535295.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409535309.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409535318.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.88,timestamp=4409535332.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409535341.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409535355.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409535364.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.27,timestamp=4409535378.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:40, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:40,optimizer_step time: 27.687936782836914
rank:40, finish optimizer.step profile ...
rank:40, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:40, trace log has been written to txt...
rank:40, finish release GPU memory ...
rank:40, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 41, finish warm up ...
rank_id = 41, input_tensor_shapes: [(2048, 2, 8192)]
rank:41,cuda fwd time: 114.88153839111328
rank:41, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409536593.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409536598.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409536604.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409536609.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409536615.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409536619.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409536626.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409536630.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409536637.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.52,timestamp=4409536641.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409536652.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409536656.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409536663.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.73,timestamp=4409536668.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409536674.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409536679.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409536685.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409536690.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409536696.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409536701.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 41, finish FWD profile ...
rank:41, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.75,timestamp=4409536709.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.57,timestamp=4409536726.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409536735.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.65,timestamp=4409536749.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409536757.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409536771.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409536780.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.66,timestamp=4409536793.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409536802.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409536816.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409536825.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409536838.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409536847.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.16,timestamp=4409536861.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.53,timestamp=4409536870.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409536884.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409536893.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409536907.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409536916.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409536930.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:41, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:41,optimizer_step time: 27.848703384399414
rank:41, finish optimizer.step profile ...
rank:41, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:41, trace log has been written to txt...
rank:41, finish release GPU memory ...
rank:41, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 42, finish warm up ...
rank_id = 42, input_tensor_shapes: [(2048, 2, 8192)]
rank:42,cuda fwd time: 111.03948974609375
rank:42, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.65,timestamp=4409538130.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409538135.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409538141.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409538146.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409538152.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409538157.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.36,timestamp=4409538163.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409538167.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409538174.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409538179.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409538185.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409538190.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.29,timestamp=4409538196.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409538201.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.28,timestamp=4409538207.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409538212.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409538219.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409538223.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409538230.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409538235.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 42, finish FWD profile ...
rank:42, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.85,timestamp=4409538243.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.19,timestamp=4409538257.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409538266.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.12,timestamp=4409538280.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409538289.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409538303.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409538312.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409538326.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409538335.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.32,timestamp=4409538349.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409538358.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409538372.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409538381.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409538394.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409538403.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409538417.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409538426.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409538440.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409538449.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409538463.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:42, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:42,optimizer_step time: 27.691007614135742
rank:42, finish optimizer.step profile ...
rank:42, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:42, trace log has been written to txt...
rank:42, finish release GPU memory ...
rank:42, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 43, finish warm up ...
rank_id = 43, input_tensor_shapes: [(2048, 2, 8192)]
rank:43,cuda fwd time: 116.79129791259766
rank:43, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409539601.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409539606.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409539612.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409539617.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409539623.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409539628.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409539634.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409539639.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409539645.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409539650.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.22,timestamp=4409539656.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409539661.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409539667.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409539672.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.15,timestamp=4409539678.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.0,timestamp=4409539688.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.94,timestamp=4409539696.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.34,timestamp=4409539700.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409539707.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409539711.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 43, finish FWD profile ...
rank:43, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.7,timestamp=4409539720.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.92,timestamp=4409539733.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409539742.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409539756.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409539765.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409539779.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409539788.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.13,timestamp=4409539803.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409539812.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.45,timestamp=4409539826.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409539835.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409539849.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409539858.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409539872.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409539881.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409539895.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409539904.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409539917.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409539927.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.14,timestamp=4409539941.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:43, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:43,optimizer_step time: 27.7708797454834
rank:43, finish optimizer.step profile ...
rank:43, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:43, trace log has been written to txt...
rank:43, finish release GPU memory ...
rank:43, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 44, finish warm up ...
rank_id = 44, input_tensor_shapes: [(2048, 2, 8192)]
rank:44,cuda fwd time: 111.77471923828125
rank:44, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409541180.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409541184.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409541190.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409541195.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.02,timestamp=4409541201.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409541206.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409541212.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409541217.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409541223.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409541228.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409541235.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409541239.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409541246.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409541251.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409541257.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409541262.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409541268.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409541273.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409541280.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409541284.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 44, finish FWD profile ...
rank:44, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.86,timestamp=4409541293.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.13,timestamp=4409541307.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409541316.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409541329.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409541338.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409541352.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409541361.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.89,timestamp=4409541375.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409541384.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409541398.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409541407.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409541421.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409541430.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409541444.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409541453.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.02,timestamp=4409541467.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409541476.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409541490.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409541500.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409541514.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:44, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:44,optimizer_step time: 27.795455932617188
rank:44, finish optimizer.step profile ...
rank:44, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:44, trace log has been written to txt...
rank:44, finish release GPU memory ...
rank:44, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 45, finish warm up ...
rank_id = 45, input_tensor_shapes: [(2048, 2, 8192)]
rank:45,cuda fwd time: 110.993408203125
rank:45, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.65,timestamp=4409542699.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409542704.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409542710.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409542715.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409542721.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409542725.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409542732.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409542736.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409542743.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409542747.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409542754.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409542759.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409542765.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409542770.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.25,timestamp=4409542776.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409542781.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.2,timestamp=4409542787.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409542792.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409542799.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.24,timestamp=4409542803.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 45, finish FWD profile ...
rank:45, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.82,timestamp=4409542812.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.9,timestamp=4409542825.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409542834.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409542848.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409542857.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409542871.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409542880.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409542894.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409542902.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409542916.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409542925.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409542939.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409542948.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409542962.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409542971.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409542985.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409542994.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.48,timestamp=4409543008.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409543017.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409543031.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:45, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:45,optimizer_step time: 27.75551986694336
rank:45, finish optimizer.step profile ...
rank:45, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:45, trace log has been written to txt...
rank:45, finish release GPU memory ...
rank:45, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 46, finish warm up ...
rank_id = 46, input_tensor_shapes: [(2048, 2, 8192)]
rank:46,cuda fwd time: 111.45420837402344
rank:46, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.62,timestamp=4409544186.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409544191.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.09,timestamp=4409544197.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409544202.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409544208.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409544212.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.29,timestamp=4409544219.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409544223.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409544230.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409544234.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.23,timestamp=4409544241.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409544246.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409544252.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409544257.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409544264.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409544268.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409544275.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409544280.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.33,timestamp=4409544286.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409544291.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 46, finish FWD profile ...
rank:46, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409544299.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.17,timestamp=4409544313.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409544322.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.93,timestamp=4409544336.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409544345.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.03,timestamp=4409544359.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409544368.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.09,timestamp=4409544382.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409544391.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409544405.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409544414.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409544427.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409544436.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409544450.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409544459.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409544472.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409544481.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.77,timestamp=4409544495.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409544504.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409544517.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:46, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:46,optimizer_step time: 27.6889591217041
rank:46, finish optimizer.step profile ...
rank:46, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:46, trace log has been written to txt...
rank:46, finish release GPU memory ...
rank:46, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 5): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 47, finish warm up ...
rank_id = 47, input_tensor_shapes: [(2048, 2, 8192)]
rank:47,cuda fwd time: 111.88121795654297
rank:47, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.43,timestamp=4409545732.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409545737.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.92,timestamp=4409545743.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409545748.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.96,timestamp=4409545754.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409545758.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.07,timestamp=4409545764.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.74,timestamp=4409545769.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409545776.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409545780.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409545787.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409545792.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409545798.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409545803.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.07,timestamp=4409545809.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409545814.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409545821.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409545826.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409545832.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409545837.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 47, finish FWD profile ...
rank:47, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409545845.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.1,timestamp=4409545859.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409545868.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409545882.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409545891.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409545905.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409545914.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409545928.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409545937.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409545951.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409545960.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.78,timestamp=4409545974.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409545982.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409545996.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409546005.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.23,timestamp=4409546020.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.66,timestamp=4409546029.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.26,timestamp=4409546043.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.68,timestamp=4409546052.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.15,timestamp=4409546066.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:47, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:47,optimizer_step time: 27.93267250061035
rank:47, finish optimizer.step profile ...
rank:47, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:47, trace log has been written to txt...
rank:47, finish release GPU memory ...
rank:47, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 48, finish warm up ...
rank_id = 48, input_tensor_shapes: [(2048, 2, 8192)]
rank:48,cuda fwd time: 114.87948608398438
rank:48, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.55,timestamp=4409547297.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409547302.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409547308.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409547313.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409547319.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409547324.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409547330.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409547334.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409547341.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409547346.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409547352.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409547357.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409547363.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.76,timestamp=4409547368.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409547374.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.0,timestamp=4409547383.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409547389.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.77,timestamp=4409547394.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409547401.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409547405.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 48, finish FWD profile ...
rank:48, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.78,timestamp=4409547414.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=11.95,timestamp=4409547427.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.2,timestamp=4409547436.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409547450.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409547459.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409547473.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409547482.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409547496.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.66,timestamp=4409547505.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.26,timestamp=4409547519.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.67,timestamp=4409547528.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.27,timestamp=4409547542.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.67,timestamp=4409547552.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.27,timestamp=4409547566.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.67,timestamp=4409547575.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409547589.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409547598.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409547612.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409547621.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409547634.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:48, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:48,optimizer_step time: 27.74118423461914
rank:48, finish optimizer.step profile ...
rank:48, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:48, trace log has been written to txt...
rank:48, finish release GPU memory ...
rank:48, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 49, finish warm up ...
rank_id = 49, input_tensor_shapes: [(2048, 2, 8192)]
rank:49,cuda fwd time: 112.21708679199219
rank:49, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409548884.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409548888.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409548895.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409548899.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409548905.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409548910.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409548916.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409548921.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409548927.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409548932.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409548939.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409548943.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409548950.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409548955.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409548962.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409548966.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409548973.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409548978.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409548984.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409548989.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 49, finish FWD profile ...
rank:49, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409548998.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.15,timestamp=4409549012.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409549021.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409549034.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409549044.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409549058.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409549067.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409549081.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409549090.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.06,timestamp=4409549104.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409549113.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.85,timestamp=4409549127.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409549135.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.15,timestamp=4409549149.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409549158.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.7,timestamp=4409549172.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.24,timestamp=4409549180.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.8,timestamp=4409549194.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409549203.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409549217.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:49, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:49,optimizer_step time: 27.825151443481445
rank:49, finish optimizer.step profile ...
rank:49, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:49, trace log has been written to txt...
rank:49, finish release GPU memory ...
rank:49, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 50, finish warm up ...
rank_id = 50, input_tensor_shapes: [(2048, 2, 8192)]
rank:50,cuda fwd time: 111.85049438476562
rank:50, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.51,timestamp=4409550444.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409550449.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.96,timestamp=4409550455.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409550460.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409550466.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409550470.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409550477.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.73,timestamp=4409550481.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.9,timestamp=4409550488.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409550492.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409550499.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409550504.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409550510.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409550515.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409550522.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409550526.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409550533.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409550538.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409550544.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409550549.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 50, finish FWD profile ...
rank:50, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409550557.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.13,timestamp=4409550571.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409550580.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409550594.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409550603.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409550617.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.12,timestamp=4409550626.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409550640.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409550649.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409550663.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409550672.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409550686.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409550695.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409550709.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409550718.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409550731.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409550740.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409550754.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.51,timestamp=4409550763.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.12,timestamp=4409550777.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:50, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:50,optimizer_step time: 27.898880004882812
rank:50, finish optimizer.step profile ...
rank:50, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:50, trace log has been written to txt...
rank:50, finish release GPU memory ...
rank:50, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 51, finish warm up ...
rank_id = 51, input_tensor_shapes: [(2048, 2, 8192)]
rank:51,cuda fwd time: 112.18637084960938
rank:51, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.51,timestamp=4409552024.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409552028.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409552035.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409552039.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409552045.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409552050.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409552056.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409552061.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409552067.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409552072.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.12,timestamp=4409552079.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409552083.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409552090.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409552095.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409552101.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409552106.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409552113.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409552118.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409552124.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409552129.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 51, finish FWD profile ...
rank:51, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.87,timestamp=4409552137.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.09,timestamp=4409552151.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409552160.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.1,timestamp=4409552174.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409552183.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409552197.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409552207.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409552221.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409552230.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.19,timestamp=4409552244.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409552253.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409552267.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409552276.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409552289.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409552298.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.79,timestamp=4409552312.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409552321.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.98,timestamp=4409552335.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409552344.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.14,timestamp=4409552358.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:51, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:51,optimizer_step time: 27.869184494018555
rank:51, finish optimizer.step profile ...
rank:51, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:51, trace log has been written to txt...
rank:51, finish release GPU memory ...
rank:51, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 52, finish warm up ...
rank_id = 52, input_tensor_shapes: [(2048, 2, 8192)]
rank:52,cuda fwd time: 111.72249603271484
rank:52, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409553547.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409553552.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409553558.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409553563.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.15,timestamp=4409553569.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409553573.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.32,timestamp=4409553580.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409553584.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409553591.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409553595.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.3,timestamp=4409553602.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409553607.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.41,timestamp=4409553613.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409553618.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.4,timestamp=4409553625.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409553629.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409553636.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409553641.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.4,timestamp=4409553647.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409553652.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 52, finish FWD profile ...
rank:52, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.37,timestamp=4409553661.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=10.73,timestamp=4409553675.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409553684.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.9,timestamp=4409553698.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409553707.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.83,timestamp=4409553721.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.29,timestamp=4409553729.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409553743.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409553752.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.75,timestamp=4409553765.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.31,timestamp=4409553774.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.94,timestamp=4409553788.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.15,timestamp=4409553797.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.54,timestamp=4409553811.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.54,timestamp=4409553820.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409553834.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409553844.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409553858.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409553867.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409553881.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:52, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:52,optimizer_step time: 27.653120040893555
rank:52, finish optimizer.step profile ...
rank:52, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:52, trace log has been written to txt...
rank:52, finish release GPU memory ...
rank:52, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 53, finish warm up ...
rank_id = 53, input_tensor_shapes: [(2048, 2, 8192)]
rank:53,cuda fwd time: 112.06348419189453
rank:53, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.65,timestamp=4409555014.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409555019.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.1,timestamp=4409555025.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409555030.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409555036.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409555041.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.36,timestamp=4409555047.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.81,timestamp=4409555051.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.19,timestamp=4409555058.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.0,timestamp=4409555063.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.13,timestamp=4409555070.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409555075.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.24,timestamp=4409555081.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409555086.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.23,timestamp=4409555092.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409555097.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.31,timestamp=4409555104.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409555108.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.27,timestamp=4409555115.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409555120.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 53, finish FWD profile ...
rank:53, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409555128.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.13,timestamp=4409555142.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409555151.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409555165.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409555174.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.07,timestamp=4409555188.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409555197.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409555211.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409555220.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.97,timestamp=4409555234.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409555243.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.16,timestamp=4409555257.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.57,timestamp=4409555266.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.08,timestamp=4409555280.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.26,timestamp=4409555289.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409555303.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409555312.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.76,timestamp=4409555326.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409555335.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.0,timestamp=4409555348.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:53, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:53,optimizer_step time: 27.78009605407715
rank:53, finish optimizer.step profile ...
rank:53, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:53, trace log has been written to txt...
rank:53, finish release GPU memory ...
rank:53, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 54, finish warm up ...
rank_id = 54, input_tensor_shapes: [(2048, 2, 8192)]
rank:54,cuda fwd time: 111.59552001953125
rank:54, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409556513.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409556518.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.11,timestamp=4409556524.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409556529.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.14,timestamp=4409556535.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409556539.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.34,timestamp=4409556545.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409556550.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.18,timestamp=4409556557.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409556561.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.34,timestamp=4409556568.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409556573.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.38,timestamp=4409556579.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409556584.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.42,timestamp=4409556590.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409556595.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.39,timestamp=4409556602.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409556607.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.37,timestamp=4409556613.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409556618.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 54, finish FWD profile ...
rank:54, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409556626.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.11,timestamp=4409556640.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.34,timestamp=4409556649.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.91,timestamp=4409556663.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409556672.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.95,timestamp=4409556686.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.49,timestamp=4409556695.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.13,timestamp=4409556709.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409556718.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.82,timestamp=4409556732.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409556741.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409556755.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409556764.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.84,timestamp=4409556778.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409556787.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.73,timestamp=4409556800.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409556809.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409556823.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.4,timestamp=4409556832.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.05,timestamp=4409556846.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:54, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:54,optimizer_step time: 27.699199676513672
rank:54, finish optimizer.step profile ...
rank:54, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:54, trace log has been written to txt...
rank:54, finish release GPU memory ...
rank:54, After memory release - Allocated: 16955311104, Reserved: 26010976256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 6): 1007196160
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1007196160 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 55, finish warm up ...
rank_id = 55, input_tensor_shapes: [(2048, 2, 8192)]
rank:55,cuda fwd time: 112.00819396972656
rank:55, fwd_subop num: 20, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409558077.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.96,timestamp=4409558082.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.94,timestamp=4409558088.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409558093.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.02,timestamp=4409558099.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.04,timestamp=4409558104.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.1,timestamp=4409558110.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409558114.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409558121.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409558126.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409558132.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409558137.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409558143.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409558148.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409558154.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409558159.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409558166.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.69,timestamp=4409558171.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409558178.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.84,timestamp=4409558182.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 55, finish FWD profile ...
rank:55, bwd_subop num: 20, bwd_subop: ['trace_src_func=allreduce,duration=5.88,timestamp=4409558190.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.24,timestamp=4409558204.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409558214.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409558228.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409558237.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409558250.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409558259.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409558273.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409558282.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.04,timestamp=4409558296.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409558305.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.86,timestamp=4409558319.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409558328.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.92,timestamp=4409558341.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409558350.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.11,timestamp=4409558364.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409558374.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.18,timestamp=4409558388.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409558397.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=13.17,timestamp=4409558411.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:55, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:55,optimizer_step time: 27.864063262939453
rank:55, finish optimizer.step profile ...
rank:55, Before memory release - Allocated: 33473104384, Reserved: 48261758976
rank:55, trace log has been written to txt...
rank:55, finish release GPU memory ...
rank:55, After memory release - Allocated: 16955311104, Reserved: 25742540800
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff400 recvbuff 0x7fd2933ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff400,7fd2933ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff200 recvbuff 0x7fd2933ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff200,7fd2933ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd004000000 recvbuff 0x7fd004000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd004000000,7fd004000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 56, finish warm up ...
rank_id = 56, input_tensor_shapes: [(2048, 2, 8192)]
rank:56,cuda fwd time: 137.2202911376953
rank:56, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409559734.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409559739.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409559745.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409559750.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.09,timestamp=4409559756.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.02,timestamp=4409559761.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409559767.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409559771.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409559778.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409559782.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.92,timestamp=4409559789.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409559793.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409559800.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409559805.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409559811.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.41,timestamp=4409559816.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.95,timestamp=4409559823.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409559828.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.04,timestamp=4409559834.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.44,timestamp=4409559839.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=23.55,timestamp=4409559864.5,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.04,timestamp=4409559865.11,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.16,timestamp=4409559865.37,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 56, finish FWD profile ...
rank:56, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.78,timestamp=4409559889.85,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=28.79,timestamp=4409559919.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.27,timestamp=4409559933.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409559942.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409559955.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.21,timestamp=4409559964.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.72,timestamp=4409559978.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409559986.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.65,timestamp=4409560000.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409560008.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.65,timestamp=4409560022.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.15,timestamp=4409560031.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409560044.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.16,timestamp=4409560053.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.66,timestamp=4409560066.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.15,timestamp=4409560075.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.64,timestamp=4409560089.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.14,timestamp=4409560097.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.64,timestamp=4409560111.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.15,timestamp=4409560120.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.63,timestamp=4409560133.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:56, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:56,optimizer_step time: 23.70355224609375
rank:56, finish optimizer.step profile ...
rank:56, Before memory release - Allocated: 25559452672, Reserved: 49239031808
rank:56, trace log has been written to txt...
rank:56, finish release GPU memory ...
rank:56, After memory release - Allocated: 8763655168, Reserved: 21816672256
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ff800 recvbuff 0x7fd2933ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ff800,7fd2933ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffa00 recvbuff 0x7fd2933ffa00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffa00,7fd2933ffa00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffc00 recvbuff 0x7fd2933ffc00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffc00,7fd2933ffc00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc814000000 recvbuff 0x7fc814000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc814000000,7fc814000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff800 recvbuff 0x7fcf009ff800 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff800,7fcf009ff800,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 57, finish warm up ...
rank_id = 57, input_tensor_shapes: [(2048, 2, 8192)]
rank:57,cuda fwd time: 144.76800537109375
rank:57, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.49,timestamp=4409561471.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.95,timestamp=4409561476.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409561482.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409561487.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.99,timestamp=4409561493.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409561497.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.01,timestamp=4409561504.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409561508.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.51,timestamp=4409561514.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.42,timestamp=4409561519.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.86,timestamp=4409561527.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.3,timestamp=4409561531.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.38,timestamp=4409561539.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.21,timestamp=4409561549.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.35,timestamp=4409561558.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.28,timestamp=4409561562.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.73,timestamp=4409561569.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.28,timestamp=4409561573.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.05,timestamp=4409561580.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.29,timestamp=4409561585.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.81,timestamp=4409561609.21,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.04,timestamp=4409561609.82,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.17,timestamp=4409561610.08,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 57, finish FWD profile ...
rank:57, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.32,timestamp=4409561634.07,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.97,timestamp=4409561662.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.12,timestamp=4409561676.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409561685.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.55,timestamp=4409561698.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409561707.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409561720.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409561729.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409561742.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409561751.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409561764.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409561773.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409561787.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409561795.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409561809.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409561817.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409561831.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409561839.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409561853.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409561862.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409561875.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:57, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:57,optimizer_step time: 24.50227165222168
rank:57, finish optimizer.step profile ...
rank:57, Before memory release - Allocated: 25971674112, Reserved: 41049653248
rank:57, trace log has been written to txt...
rank:57, finish release GPU memory ...
rank:57, After memory release - Allocated: 8763655168, Reserved: 25992101888
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd2933ffe00 recvbuff 0x7fd2933ffe00 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd2933ffe00,7fd2933ffe00,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd1ffe75000 recvbuff 0x7fd1ffe75000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd1ffe75000,7fd1ffe75000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd1ffe75200 recvbuff 0x7fd1ffe75200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd1ffe75200,7fd1ffe75200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc5f4000000 recvbuff 0x7fc5f4000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc5f4000000,7fc5f4000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd1ffe84a00 recvbuff 0x7fd1ffe84a00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd1ffe84a00,7fd1ffe84a00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 58, finish warm up ...
rank_id = 58, input_tensor_shapes: [(2048, 2, 8192)]
rank:58,cuda fwd time: 145.18374633789062
rank:58, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.54,timestamp=4409563108.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409563112.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409563118.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409563123.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409563129.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409563134.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409563140.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409563144.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.52,timestamp=4409563151.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.85,timestamp=4409563155.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.05,timestamp=4409563168.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.32,timestamp=4409563173.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.11,timestamp=4409563179.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.31,timestamp=4409563184.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.27,timestamp=4409563194.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=2.33,timestamp=4409563198.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=1.35,timestamp=4409563206.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.28,timestamp=4409563210.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.09,timestamp=4409563217.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.09,timestamp=4409563222.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.8,timestamp=4409563246.12,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.03,timestamp=4409563246.72,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.16,timestamp=4409563246.98,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 58, finish FWD profile ...
rank:58, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.31,timestamp=4409563270.96,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.96,timestamp=4409563299.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.15,timestamp=4409563313.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409563322.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409563335.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409563344.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409563357.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409563366.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409563379.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409563388.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409563401.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409563410.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409563423.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409563432.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409563446.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409563454.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409563468.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409563476.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409563490.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409563498.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.57,timestamp=4409563512.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:58, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fd1ffe84a00 recvbuff 0x7fd1ffe84a00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fd1ffe84a00,7fd1ffe84a00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:58,optimizer_step time: 23.615488052368164
rank:58, finish optimizer.step profile ...
rank:58, Before memory release - Allocated: 25971674112, Reserved: 41055944704
rank:58, trace log has been written to txt...
rank:58, finish release GPU memory ...
rank:58, After memory release - Allocated: 8763655168, Reserved: 21627928576
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc98e000000 recvbuff 0x7fc98e000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc98e000000,7fc98e000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 59, finish warm up ...
rank_id = 59, input_tensor_shapes: [(2048, 2, 8192)]
rank:59,cuda fwd time: 134.85055541992188
rank:59, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.52,timestamp=4409564768.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409564772.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.94,timestamp=4409564779.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409564783.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.0,timestamp=4409564789.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409564794.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.51,timestamp=4409564800.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.68,timestamp=4409564805.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409564811.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.75,timestamp=4409564816.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.93,timestamp=4409564822.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409564827.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409564833.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409564838.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409564844.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.52,timestamp=4409564849.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.51,timestamp=4409564855.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.3,timestamp=4409564860.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.23,timestamp=4409564867.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.28,timestamp=4409564871.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.8,timestamp=4409564895.97,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.03,timestamp=4409564896.58,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.16,timestamp=4409564896.84,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 59, finish FWD profile ...
rank:59, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.31,timestamp=4409564921.2,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.97,timestamp=4409564950.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.0,timestamp=4409564963.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.05,timestamp=4409564972.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409564985.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409564994.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409565007.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409565016.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409565029.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409565038.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409565052.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409565060.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409565074.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409565082.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.57,timestamp=4409565096.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409565104.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409565118.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409565127.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409565140.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409565149.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409565162.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:59, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:59,optimizer_step time: 23.534591674804688
rank:59, finish optimizer.step profile ...
rank:59, Before memory release - Allocated: 25971674112, Reserved: 41070624768
rank:59, trace log has been written to txt...
rank:59, finish release GPU memory ...
rank:59, After memory release - Allocated: 8763655168, Reserved: 21533556736
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff400 recvbuff 0x7fcf009ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff400,7fcf009ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff600 recvbuff 0x7fcf009ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff600,7fcf009ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff800 recvbuff 0x7fcf009ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff800,7fcf009ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc5f4000000 recvbuff 0x7fc5f4000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc5f4000000,7fc5f4000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (4, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 60, finish warm up ...
rank_id = 60, input_tensor_shapes: [(2048, 2, 8192)]
rank:60,cuda fwd time: 137.03475952148438
rank:60, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=3.69,timestamp=4409566430.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.87,timestamp=4409566435.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.91,timestamp=4409566441.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.98,timestamp=4409566445.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.94,timestamp=4409566452.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409566456.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.4,timestamp=4409566462.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.69,timestamp=4409566467.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409566473.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409566478.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.37,timestamp=4409566485.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.7,timestamp=4409566489.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409566496.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.72,timestamp=4409566500.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.85,timestamp=4409566507.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409566511.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.16,timestamp=4409566518.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.26,timestamp=4409566522.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.04,timestamp=4409566529.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.15,timestamp=4409566535.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.69,timestamp=4409566559.4,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.04,timestamp=4409566560.15,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.16,timestamp=4409566560.44,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 60, finish FWD profile ...
rank:60, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.31,timestamp=4409566584.93,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.93,timestamp=4409566613.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.04,timestamp=4409566627.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409566636.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409566649.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409566658.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409566671.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409566680.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409566693.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409566702.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409566715.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409566724.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409566737.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409566746.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409566760.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409566768.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409566782.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409566790.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409566804.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409566812.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409566826.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:60, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:60,optimizer_step time: 24.187904357910156
rank:60, finish optimizer.step profile ...
rank:60, Before memory release - Allocated: 25971674112, Reserved: 41060139008
rank:60, trace log has been written to txt...
rank:60, finish release GPU memory ...
rank:60, After memory release - Allocated: 8763655168, Reserved: 21801992192
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc95a000000 recvbuff 0x7fc95a000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc95a000000,7fc95a000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (5, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 61, finish warm up ...
rank_id = 61, input_tensor_shapes: [(2048, 2, 8192)]
rank:61,cuda fwd time: 135.18540954589844
rank:61, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.53,timestamp=4409568083.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.94,timestamp=4409568088.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.95,timestamp=4409568094.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409568098.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.97,timestamp=4409568105.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.0,timestamp=4409568109.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.49,timestamp=4409568115.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.67,timestamp=4409568120.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.86,timestamp=4409568126.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409568131.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.91,timestamp=4409568137.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.74,timestamp=4409568142.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.89,timestamp=4409568149.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.71,timestamp=4409568153.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.88,timestamp=4409568160.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.49,timestamp=4409568164.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.42,timestamp=4409568171.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.27,timestamp=4409568176.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.23,timestamp=4409568182.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.28,timestamp=4409568187.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.8,timestamp=4409568211.46,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.04,timestamp=4409568212.08,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.16,timestamp=4409568212.35,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 61, finish FWD profile ...
rank:61, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.31,timestamp=4409568236.36,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.97,timestamp=4409568265.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.16,timestamp=4409568278.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409568287.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409568300.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409568309.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409568322.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409568331.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409568345.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409568353.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409568367.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409568375.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409568389.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409568397.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409568411.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409568420.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409568433.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409568442.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409568455.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409568464.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.62,timestamp=4409568477.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:61, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffc00 recvbuff 0x7fcf009ffc00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffc00,7fcf009ffc00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:61,optimizer_step time: 23.613439559936523
rank:61, finish optimizer.step profile ...
rank:61, Before memory release - Allocated: 25971674112, Reserved: 41060139008
rank:61, trace log has been written to txt...
rank:61, finish release GPU memory ...
rank:61, After memory release - Allocated: 8763655168, Reserved: 21801992192
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff400 recvbuff 0x7fcf009ff400 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff400,7fcf009ff400,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff600 recvbuff 0x7fcf009ff600 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff600,7fcf009ff600,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff800 recvbuff 0x7fcf009ff800 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff800,7fcf009ff800,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcb64000000 recvbuff 0x7fcb64000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcb64000000,7fcb64000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (6, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffa00 recvbuff 0x7fcf009ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffa00,7fcf009ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 62, finish warm up ...
rank_id = 62, input_tensor_shapes: [(2048, 2, 8192)]
rank:62,cuda fwd time: 134.16140747070312
rank:62, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.64,timestamp=4409569697.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409569701.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409569707.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409569712.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.13,timestamp=4409569718.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409569723.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.67,timestamp=4409569729.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409569733.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.11,timestamp=4409569740.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409569744.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.21,timestamp=4409569751.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.8,timestamp=4409569755.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.17,timestamp=4409569762.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.82,timestamp=4409569766.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.97,timestamp=4409569773.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.38,timestamp=4409569777.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.78,timestamp=4409569784.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.38,timestamp=4409569788.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.45,timestamp=4409569795.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.39,timestamp=4409569800.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.83,timestamp=4409569824.07,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.03,timestamp=4409569824.64,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.17,timestamp=4409569824.89,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 62, finish FWD profile ...
rank:62, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.32,timestamp=4409569848.97,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=28.01,timestamp=4409569877.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.15,timestamp=4409569891.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.05,timestamp=4409569900.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409569913.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409569922.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409569935.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409569944.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409569957.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409569966.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409569979.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409569988.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409570001.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409570010.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409570024.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409570032.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409570046.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409570054.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409570068.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409570076.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.56,timestamp=4409570090.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:62, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffa00 recvbuff 0x7fcf009ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffa00,7fcf009ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:62,optimizer_step time: 23.48953628540039
rank:62, finish optimizer.step profile ...
rank:62, Before memory release - Allocated: 25971674112, Reserved: 41076916224
rank:62, trace log has been written to txt...
rank:62, finish release GPU memory ...
rank:62, After memory release - Allocated: 8763655168, Reserved: 21594374144
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      20
    validation: 2
    test:       2
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(20, 2, 2), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7fd30c0a3880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from af0c292c27849f3ba008a4ed16ee6d02-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 293a6bd97906b1bd25135bd44457fa68-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff000 recvbuff 0x7fcf009ff000 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff000,7fcf009ff000,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 11438c5224f9b104e85fd3df0d4aba80-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ff200 recvbuff 0x7fcf009ff200 count 1 datatype 1 op 0 root 0 comm 0x90cf8f0 [nranks=1] stream 0x88df4d0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ff200,7fcf009ff200,1,1,0,0,0x90cf8f0,0x88df4d0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fc94c000000 recvbuff 0x7fc94c000000 count 51511296 datatype 7 op 0 root 0 comm 0xd1661f0 [nranks=1] stream 0x90e64b0
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fc94c000000,7fc94c000000,51511296,7,0,0,0xd1661f0,0x90e64b0)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (7, 7): 1058723840
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1058723840 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    output_layer.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.final_layernorm.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.6.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.7.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.9.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.8.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7fd30c0fe820>)
> learning rate decay style: cosine
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffa00 recvbuff 0x7fcf009ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffa00,7fcf009ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank_id = 63, finish warm up ...
rank_id = 63, input_tensor_shapes: [(2048, 2, 8192)]
rank:63,cuda fwd time: 135.30931091308594
rank:63, fwd_subop num: 23, fwd_subop: ['trace_src_func=allreduce,duration=4.63,timestamp=4409571309.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.01,timestamp=4409571313.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.07,timestamp=4409571319.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.05,timestamp=4409571324.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.12,timestamp=4409571330.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.06,timestamp=4409571335.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.68,timestamp=4409571341.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.03,timestamp=4409571345.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409571352.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.79,timestamp=4409571357.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.15,timestamp=4409571363.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409571367.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.14,timestamp=4409571374.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.83,timestamp=4409571378.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.99,timestamp=4409571385.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.58,timestamp=4409571389.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.35,timestamp=4409571396.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.4,timestamp=4409571401.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.32,timestamp=4409571407.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=3.33,timestamp=4409571412.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=22.81,timestamp=4409571437.27,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_1,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.03,timestamp=4409571437.83,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_2,group=tp,comm_func=allreduce', 'trace_src_func=_reduce,duration=0.17,timestamp=4409571438.08,input__shape=[2048, 2],input__dtype=torch.float32,func_name=crossEntropy_fwd_3,group=tp,comm_func=allreduce']
rank_id = 63, finish FWD profile ...
rank:63, bwd_subop num: 21, bwd_subop: ['trace_src_func=allreduce,duration=22.32,timestamp=4409571462.23,input__shape=[2048, 2, 8192],input__dtype=torch.float32,func_name=embedding_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=27.98,timestamp=4409571491.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.19,timestamp=4409571504.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409571513.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.58,timestamp=4409571526.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409571535.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409571548.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409571557.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409571570.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409571579.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409571593.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409571601.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409571615.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409571623.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409571637.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409571645.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.6,timestamp=4409571659.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409571668.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.61,timestamp=4409571681.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409571690.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=12.59,timestamp=4409571703.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:63, finish BWD profile ...
proj187:3289979:3289979 NCCL CALL ncclGroupStart()
proj187:3289979:3289979 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7fcf009ffa00 recvbuff 0x7fcf009ffa00 count 1 datatype 7 op 0 root 0 comm 0x19628f40 [nranks=1] stream 0x90ef430
proj187:3289979:3289979 NCCL CALL ncclAllReduce(7fcf009ffa00,7fcf009ffa00,1,7,0,0,0x19628f40,0x90ef430)
proj187:3289979:3289979 NCCL CALL ncclGroupEnd()
rank:63,optimizer_step time: 23.458816528320312
rank:63, finish optimizer.step profile ...
rank:63, Before memory release - Allocated: 25971674112, Reserved: 41070624768
rank:63, trace log has been written to txt...
rank:63, finish release GPU memory ...
rank:63, After memory release - Allocated: 8763655168, Reserved: 21862809600
