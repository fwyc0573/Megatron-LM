using world size: 1, data-parallel size: 1, context-parallel size: 1 tensor-model-parallel size: 1, pipeline-model-parallel size: 1 
WARNING: Setting args.overlap_p2p_comm to False since non-interleaved schedule does not support overlapping p2p communication
using torch.float32 for parameters ...
------------------------ arguments ------------------------
  accumulate_allreduce_grads_in_fp32 .............. False
  adam_beta1 ...................................... 0.9
  adam_beta2 ...................................... 0.999
  adam_eps ........................................ 1e-08
  add_bias_linear ................................. True
  add_position_embedding .......................... True
  add_qkv_bias .................................... False
  adlr_autoresume ................................. False
  adlr_autoresume_interval ........................ 1000
  apply_layernorm_1p .............................. False
  apply_query_key_layer_scaling ................... False
  apply_residual_connection_post_layernorm ........ False
  apply_rope_fusion ............................... True
  async_tensor_model_parallel_allreduce ........... True
  attention_dropout ............................... 0.1
  attention_softmax_in_fp32 ....................... False
  auto_detect_ckpt_format ......................... False
  barrier_with_L1_time ............................ True
  bert_binary_head ................................ True
  bert_embedder_type .............................. megatron
  bert_load ....................................... None
  bf16 ............................................ False
  bias_dropout_fusion ............................. True
  bias_gelu_fusion ................................ True
  bias_swiglu_fusion .............................. True
  biencoder_projection_dim ........................ 0
  biencoder_shared_query_context_model ............ False
  block_data_path ................................. None
  check_for_nan_in_loss_and_grad .................. True
  check_weight_hash_across_dp_replicas_interval ... None
  ckpt_fully_parallel_save ........................ False
  ckpt_step ....................................... None
  classes_fraction ................................ 1.0
  clip_grad ....................................... 1.0
  clone_scatter_output_in_embedding ............... True
  consumed_train_samples .......................... 0
  consumed_valid_samples .......................... 0
  context_parallel_size ........................... 1
  create_attention_mask_in_dataloader ............. True
  data_cache_path ................................. None
  data_parallel_random_init ....................... False
  data_parallel_size .............................. 1
  data_path ....................................... ['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document']
  data_per_class_fraction ......................... 1.0
  data_sharding ................................... True
  dataloader_type ................................. single
  ddp_bucket_size ................................. None
  decoder_num_layers .............................. None
  decoder_seq_length .............................. None
  decoupled_lr .................................... None
  decoupled_min_lr ................................ None
  delay_grad_reduce ............................... True
  delay_param_gather .............................. False
  dino_bottleneck_size ............................ 256
  dino_freeze_last_layer .......................... 1
  dino_head_hidden_size ........................... 2048
  dino_local_crops_number ......................... 10
  dino_local_img_size ............................. 96
  dino_norm_last_layer ............................ False
  dino_teacher_temp ............................... 0.07
  dino_warmup_teacher_temp ........................ 0.04
  dino_warmup_teacher_temp_epochs ................. 30
  disable_straggler_on_startup .................... False
  dist_ckpt_format ................................ torch_dist
  distribute_saved_activations .................... False
  distributed_backend ............................. nccl
  distributed_timeout_minutes ..................... 10
  do_trace ........................................ True
  embedding_path .................................. None
  empty_unused_memory_level ....................... 0
  enable_one_logger ............................... False
  encoder_num_layers .............................. 80
  encoder_seq_length .............................. 2048
  end_weight_decay ................................ 0.01
  eod_mask_loss ................................... False
  eval_interval ................................... 1000
  eval_iters ...................................... 1
  evidence_data_path .............................. None
  exit_duration_in_mins ........................... None
  exit_interval ................................... None
  exit_on_missing_checkpoint ...................... False
  exit_signal_handler ............................. False
  expert_model_parallel_size ...................... 1
  fake_dp ......................................... 2
  fake_gpus_per_node .............................. 8
  fake_local_rank ................................. 0
  fake_pp ......................................... 12
  fake_tp ......................................... 4
  fake_world_size ................................. 96
  fake_wrank ...................................... 0
  ffn_hidden_size ................................. 32768
  finetune ........................................ False
  fp16 ............................................ False
  fp16_lm_cross_entropy ........................... False
  fp32_residual_connection ........................ False
  fp8 ............................................. None
  fp8_amax_compute_algo ........................... most_recent
  fp8_amax_history_len ............................ 1
  fp8_interval .................................... 1
  fp8_margin ...................................... 0
  fp8_wgrad ....................................... True
  global_batch_size ............................... 4
  gradient_accumulation_fusion .................... True
  group_query_attention ........................... False
  head_lr_mult .................................... 1.0
  hidden_dropout .................................. 0.1
  hidden_size ..................................... 8192
  hysteresis ...................................... 2
  ict_head_size ................................... None
  ict_load ........................................ None
  img_h ........................................... 224
  img_w ........................................... 224
  indexer_batch_size .............................. 128
  indexer_log_interval ............................ 1000
  inference_batch_times_seqlen_threshold .......... 512
  init_method_std ................................. 0.02
  init_method_xavier_uniform ...................... False
  initial_loss_scale .............................. 4294967296
  is_scaling_mode ................................. True
  iter_per_epoch .................................. 1250
  kv_channels ..................................... 128
  lazy_mpu_init ................................... None
  load ............................................ None
  local_rank ...................................... None
  log_batch_size_to_tensorboard ................... False
  log_interval .................................... 100
  log_learning_rate_to_tensorboard ................ True
  log_loss_scale_to_tensorboard ................... True
  log_memory_to_tensorboard ....................... False
  log_num_zeros_in_grad ........................... False
  log_params_norm ................................. False
  log_progress .................................... False
  log_straggler ................................... False
  log_throughput .................................. False
  log_timers_to_tensorboard ....................... False
  log_validation_ppl_to_tensorboard ............... False
  log_world_size_to_tensorboard ................... False
  loss_scale ...................................... None
  loss_scale_window ............................... 1000
  lr .............................................. 0.00015
  lr_decay_iters .................................. 320000
  lr_decay_samples ................................ None
  lr_decay_style .................................. cosine
  lr_warmup_fraction .............................. 0.01
  lr_warmup_init .................................. 0.0
  lr_warmup_iters ................................. 0
  lr_warmup_samples ............................... 0
  main_tokenizer_type ............................. GPT2BPETokenizer
  make_vocab_size_divisible_by .................... 128
  manual_gc ....................................... False
  manual_gc_eval .................................. True
  manual_gc_interval .............................. 0
  mask_factor ..................................... 1.0
  mask_prob ....................................... 0.15
  mask_type ....................................... random
  masked_softmax_fusion ........................... True
  max_position_embeddings ......................... 2048
  max_tokens_to_oom ............................... 12000
  merge_file ...................................... /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/gpt2-merges.txt
  micro_batch_size ................................ 2
  min_loss_scale .................................. 1.0
  min_lr .......................................... 1e-05
  mmap_bin_files .................................. True
  mock_data ....................................... False
  moe_aux_loss_coeff .............................. 0.0
  moe_grouped_gemm ................................ False
  moe_input_jitter_eps ............................ None
  moe_per_layer_logging ........................... False
  moe_router_load_balancing_type .................. aux_loss
  moe_router_topk ................................. 2
  moe_token_dispatcher_type ....................... allgather
  moe_token_dropping .............................. False
  moe_z_loss_coeff ................................ None
  nccl_communicator_config_path ................... None
  no_load_optim ................................... None
  no_load_rng ..................................... None
  no_persist_layer_norm ........................... False
  no_save_optim ................................... None
  no_save_rng ..................................... None
  norm_epsilon .................................... 1e-05
  normalization ................................... LayerNorm
  nsight_start .................................... 10
  num_attention_heads ............................. 64
  num_channels .................................... 3
  num_classes ..................................... 1000
  num_experts ..................................... None
  num_layers ...................................... 80
  num_layers_per_virtual_pipeline_stage ........... None
  num_query_groups ................................ 1
  num_workers ..................................... 2
  one_logger_entity ............................... hwinf_dcm
  one_logger_project .............................. e2e-tracking
  one_logger_run_name ............................. None
  onnx_safe ....................................... None
  openai_gelu ..................................... False
  optimizer ....................................... adam
  output_bert_embeddings .......................... False
  overlap_grad_reduce ............................. False
  overlap_p2p_comm ................................ False
  overlap_param_gather ............................ False
  override_opt_param_scheduler .................... False
  params_dtype .................................... torch.float32
  patch_dim ....................................... 16
  perform_initialization .......................... True
  pipeline_model_parallel_size .................... 1
  pipeline_model_parallel_split_rank .............. None
  position_embedding_type ......................... learned_absolute
  pretrained_checkpoint ........................... None
  profile ......................................... False
  profile_ranks ................................... [0]
  profile_step_end ................................ 12
  profile_step_start .............................. 10
  qk_layernorm .................................... False
  query_in_block_prob ............................. 0.1
  rampup_batch_size ............................... None
  rank ............................................ 0
  recompute_granularity ........................... None
  recompute_method ................................ None
  recompute_num_layers ............................ None
  reset_attention_mask ............................ False
  reset_position_ids .............................. False
  retriever_report_topk_accuracies ................ []
  retriever_score_scaling ......................... False
  retriever_seq_length ............................ 256
  retro_add_retriever ............................. False
  retro_attention_gate ............................ 1
  retro_cyclic_train_iters ........................ None
  retro_encoder_attention_dropout ................. 0.1
  retro_encoder_hidden_dropout .................... 0.1
  retro_encoder_layers ............................ 2
  retro_num_neighbors ............................. 2
  retro_num_retrieved_chunks ...................... 2
  retro_project_dir ............................... None
  retro_verify_neighbor_count ..................... True
  rotary_interleaved .............................. False
  rotary_percent .................................. 1.0
  rotary_seq_len_interpolation_factor ............. None
  sample_rate ..................................... 1.0
  save ............................................ None
  save_interval ................................... 1000
  scatter_gather_tensors_in_pipeline .............. True
  seed ............................................ 1234
  seq_length ...................................... 2048
  sequence_parallel ............................... False
  sgd_momentum .................................... 0.9
  short_seq_prob .................................. 0.1
  skip_train ...................................... False
  spec ............................................ None
  split ........................................... 949,50,1
  squared_relu .................................... False
  standalone_embedding_stage ...................... False
  start_weight_decay .............................. 0.01
  straggler_ctrlr_port ............................ 65535
  straggler_minmax_count .......................... 1
  swiglu .......................................... False
  swin_backbone_type .............................. tiny
  tensor_model_parallel_size ...................... 1
  tensorboard_dir ................................. None
  tensorboard_log_interval ........................ 1
  tensorboard_queue_size .......................... 1000
  test_data_path .................................. None
  test_mode ....................................... False
  timing_log_level ................................ 0
  timing_log_option ............................... minmax
  titles_data_path ................................ None
  tokenizer_model ................................. None
  tokenizer_type .................................. GPT2BPETokenizer
  tp_comm_bulk_dgrad .............................. True
  tp_comm_bulk_wgrad .............................. True
  tp_comm_overlap ................................. False
  tp_comm_overlap_ag .............................. True
  tp_comm_overlap_cfg ............................. None
  tp_comm_overlap_rs .............................. True
  tp_comm_overlap_rs_dgrad ........................ False
  tp_comm_split_ag ................................ True
  tp_comm_split_rs ................................ True
  trace_start ..................................... 10
  train_data_path ................................. None
  train_iters ..................................... 10
  train_samples ................................... None
  transformer_impl ................................ transformer_engine
  transformer_pipeline_model_parallel_size ........ 1
  untie_embeddings_and_output_weights ............. False
  use_checkpoint_args ............................. False
  use_checkpoint_opt_param_scheduler .............. False
  use_cpu_initialization .......................... None
  use_dist_ckpt ................................... False
  use_distributed_optimizer ....................... False
  use_flash_attn .................................. False
  use_mcore_models ................................ True
  use_one_sent_docs ............................... False
  use_ring_exchange_p2p ........................... False
  use_rotary_position_embeddings .................. False
  use_tp_pp_dp_mapping ............................ False
  valid_data_path ................................. None
  variable_seq_lengths ............................ False
  virtual_pipeline_model_parallel_size ............ None
  vision_backbone_type ............................ vit
  vision_pretraining .............................. False
  vision_pretraining_type ......................... classify
  vocab_extra_ids ................................. 0
  vocab_file ...................................... /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/gpt2-vocab.json
  vocab_size ...................................... 3200
  wandb_exp_name .................................. 
  wandb_project ................................... 
  wandb_save_dir .................................. 
  weight_decay .................................... 0.01
  weight_decay_incr_style ......................... constant
  world_size ...................................... 1
  yaml_cfg ........................................ None
-------------------- end of arguments ---------------------
setting number of micro-batches to constant 2
> building GPT2BPETokenizer tokenizer ...
 > padded vocab (size: 50257) with 47 dummy tokens (new size: 50304)
> initializing torch distributed ...
> initialized tensor model parallel with size 1
> initialized pipeline model parallel with size 1
> setting random seeds to 1234 ...
> compiling dataset index builder ...
make: Entering directory '/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/core/datasets'
make: Nothing to be done for 'default'.
make: Leaving directory '/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/core/datasets'
>>> done with dataset index builder. Compilation time: 0.051 seconds
WARNING: constraints for invoking optimized fused softmax kernel are not met. We default back to unfused kernel invocations.
> compiling and loading fused kernels ...
proj187:3284234:3284234 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ens81f0
proj187:3284234:3284234 [0] NCCL INFO NCCL_SOCKET_IFNAME set to ens81f0
proj187:3284234:3284234 [0] NCCL INFO Bootstrap : Using ens81f0:192.168.50.187<0>
proj187:3284234:3284234 [0] NCCL INFO NET/Plugin : Plugin load (libnccl-net.so) returned 2 : libnccl-net.so: cannot open shared object file: No such file or directory
proj187:3284234:3284234 [0] NCCL INFO NET/Plugin : No plugin found, using internal implementation
proj187:3284234:3284234 NCCL CALL ncclGetUniqueId(0xf6e339e582145e6c)
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO cudaDriverVersion 12020
NCCL version 2.18.6+cuda12.1
proj187:3284234:3284234 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7f90dd400000
proj187:3284234:3284477 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
proj187:3284234:3284477 [0] NCCL INFO NCCL_SOCKET_IFNAME set by environment to ens81f0
proj187:3284234:3284477 [0] NCCL INFO NET/Socket : Using [0]ens81f0:192.168.50.187<0>
proj187:3284234:3284477 [0] NCCL INFO Using network Socket
proj187:3284234:3284477 [0] NCCL INFO comm 0x8cc2b40 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xf6e339e582145e6c - Init START
proj187:3284234:3284477 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3284234:3284477 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3284234:3284477 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3284234:3284477 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3284234:3284477 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3284234:3284477 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3284234:3284477 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3284234:3284477 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3284234:3284477 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3284234:3284477 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3284234:3284477 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3284234:3284477 [0] NCCL INFO ==========================================
proj187:3284234:3284477 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3284234:3284477 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3284234:3284477 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284477 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284477 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284477 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284477 [0] NCCL INFO Channel 00/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 01/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 02/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 03/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 04/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 05/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 06/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 07/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 08/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 09/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 10/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 11/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 12/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 13/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 14/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 15/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 16/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 17/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 18/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 19/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 20/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 21/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 22/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 23/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 24/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 25/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 26/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 27/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 28/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 29/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 30/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Channel 31/32 :    0
proj187:3284234:3284477 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3284234:3284477 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3284234:3284477 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3284234:3284477 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc00000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc00200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc00400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc00600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc00800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc00a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc00c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc00e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc01000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc01200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc01400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc01600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc01800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc01a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc01c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc01e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc02000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc02200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc02400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc02600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc02800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc02a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc02c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc02e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc03000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc03200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc03400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc03600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc03800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc03a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc03c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc03e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc04000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc04200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc04400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc04600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc04800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc04a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc04c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc04e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc05000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc05200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc05400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc05600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc05800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc05a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc05c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc05e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc06000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc06200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc06400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc06600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc06800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc06a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc06c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc06e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc07000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc07200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc07400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc07600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc07800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc07a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc07c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc07e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc08000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc08200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc08400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc08600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc08800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc08a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc08c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc08e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc09000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc09200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc09400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc09600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc09800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc09a00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc09c00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc09e00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0a000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0a200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0a400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0a600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0a800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0aa00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0ac00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0ae00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0b000
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0b200
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0b400
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0b600
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0b800
proj187:3284234:3284477 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0ba00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0bc00
proj187:3284234:3284477 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0be00
proj187:3284234:3284477 [0] NCCL INFO Connected all rings
proj187:3284234:3284477 [0] NCCL INFO Connected all trees
proj187:3284234:3284477 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3284234:3284479 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7f90c0002f20
proj187:3284234:3284479 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-gTfcX1
proj187:3284234:3284479 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3284234:3284479 [0] NCCL INFO proxyProgressAsync opId=0x7f90b21b33e0 op.type=1 op.reqBuff=0x7f90c0000bb0 op.respSize=16 done
proj187:3284234:3284477 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f90b21b33e0
proj187:3284234:3284477 [0] NCCL INFO recvOpId=0x7f90b21b33e0 matches expected opId=0x7f90b21b33e0
proj187:3284234:3284479 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3284234:3284477 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7f90c0003160
proj187:3284234:3284479 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7f90aa000000
proj187:3284234:3284479 [0] NCCL INFO proxyProgressAsync opId=0x7f90b21b33e0 op.type=2 op.reqBuff=0x7f90c0005cc0 op.respSize=0 done
proj187:3284234:3284477 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f90b21b33e0
proj187:3284234:3284479 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3284234:3284477 [0] NCCL INFO recvOpId=0x7f90b21b33e0 matches expected opId=0x7f90b21b33e0
proj187:3284234:3284477 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7f90afc0c000
proj187:3284234:3284477 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7f90a2000000
proj187:3284234:3284477 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7f90dd400200
proj187:3284234:3284477 NCCL CALL ncclCommInitRank(0x8cc2b40, 1, 0xf6e339e582145e6c, 0, 0)
proj187:3284234:3284477 [0] NCCL INFO comm 0x8cc2b40 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xf6e339e582145e6c - Init COMPLETE
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200000 recvbuff 0x7f90dd200000 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200000,7f90dd200000,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
>>> done with compiling and loading fused kernels. Compilation time: 0.848 seconds
/research/d1/gds/ytyang/yichengfeng/Megatron-LM/megatron/training/initialize.py:405: UserWarning: nvfuser integration in TorchScript is deprecated. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/jit/codegen/cuda/interface.cpp:235.)
  output = bias_gelu(bias, input)
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200000 recvbuff 0x7f90dd200000 count 1 datatype 8 op 3 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200000,7f90dd200000,1,8,3,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
time to initialize megatron (seconds): 1.995
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
[after megatron is initialized] datetime: 2024-09-22 17:02:48 
mpu_info:MPUInfo:
	dp_size=2
	tp_size=4
	pp_size=12
	mp_size=48
	world_size=96
	dp_groups=[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15], [16, 20], [17, 21], [18, 22], [19, 23], [24, 28], [25, 29], [26, 30], [27, 31], [32, 36], [33, 37], [34, 38], [35, 39], [40, 44], [41, 45], [42, 46], [43, 47], [48, 52], [49, 53], [50, 54], [51, 55], [56, 60], [57, 61], [58, 62], [59, 63], [64, 68], [65, 69], [66, 70], [67, 71], [72, 76], [73, 77], [74, 78], [75, 79], [80, 84], [81, 85], [82, 86], [83, 87], [88, 92], [89, 93], [90, 94], [91, 95]]
	pp_groups=[[0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88], [1, 9, 17, 25, 33, 41, 49, 57, 65, 73, 81, 89], [2, 10, 18, 26, 34, 42, 50, 58, 66, 74, 82, 90], [3, 11, 19, 27, 35, 43, 51, 59, 67, 75, 83, 91], [4, 12, 20, 28, 36, 44, 52, 60, 68, 76, 84, 92], [5, 13, 21, 29, 37, 45, 53, 61, 69, 77, 85, 93], [6, 14, 22, 30, 38, 46, 54, 62, 70, 78, 86, 94], [7, 15, 23, 31, 39, 47, 55, 63, 71, 79, 87, 95]]
	tp_groups=[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31], [32, 33, 34, 35], [36, 37, 38, 39], [40, 41, 42, 43], [44, 45, 46, 47], [48, 49, 50, 51], [52, 53, 54, 55], [56, 57, 58, 59], [60, 61, 62, 63], [64, 65, 66, 67], [68, 69, 70, 71], [72, 73, 74, 75], [76, 77, 78, 79], [80, 81, 82, 83], [84, 85, 86, 87], [88, 89, 90, 91], [92, 93, 94, 95]]
	mp_groups=[[0, 1, 2, 3, 8, 9, 10, 11, 16, 17, 18, 19, 24, 25, 26, 27, 32, 33, 34, 35, 40, 41, 42, 43, 48, 49, 50, 51, 56, 57, 58, 59, 64, 65, 66, 67, 72, 73, 74, 75, 80, 81, 82, 83, 88, 89, 90, 91], [4, 5, 6, 7, 12, 13, 14, 15, 20, 21, 22, 23, 28, 29, 30, 31, 36, 37, 38, 39, 44, 45, 46, 47, 52, 53, 54, 55, 60, 61, 62, 63, 68, 69, 70, 71, 76, 77, 78, 79, 84, 85, 86, 87, 92, 93, 94, 95]]
	ep_groups=[[0, 88], [1, 89], [2, 90], [3, 91], [4, 92], [5, 93], [6, 94], [7, 95]]
	pep_groups=[[0], [1], [2], [3], [4], [5], [6], [7]]
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200400 recvbuff 0x7f90dd200400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200400,7f90dd200400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200400 recvbuff 0x7f90dd200400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200400,7f90dd200400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGetUniqueId(0x5302a2e6143095f)
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7f90dd470400
proj187:3284234:3284798 [0] NCCL INFO Using network Socket
proj187:3284234:3284798 [0] NCCL INFO comm 0xdbf1a30 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x5302a2e6143095f - Init START
proj187:3284234:3284798 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3284234:3284798 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3284234:3284798 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3284234:3284798 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3284234:3284798 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3284234:3284798 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3284234:3284798 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3284234:3284798 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3284234:3284798 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3284234:3284798 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3284234:3284798 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3284234:3284798 [0] NCCL INFO ==========================================
proj187:3284234:3284798 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3284234:3284798 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3284234:3284798 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284798 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284798 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284798 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284798 [0] NCCL INFO Channel 00/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 01/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 02/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 03/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 04/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 05/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 06/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 07/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 08/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 09/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 10/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 11/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 12/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 13/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 14/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 15/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 16/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 17/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 18/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 19/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 20/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 21/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 22/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 23/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 24/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 25/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 26/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 27/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 28/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 29/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 30/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Channel 31/32 :    0
proj187:3284234:3284798 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3284234:3284798 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3284234:3284798 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3284234:3284798 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0e000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0e200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0e400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0e600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0e800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0ea00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0ec00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0ee00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0f000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0f200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0f400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0f600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0f800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc0fa00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc0fc00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc0fe00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc10000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc10200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc10400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc10600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc10800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc10a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc10c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc10e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc11000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc11200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc11400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc11600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc11800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc11a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc11c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc11e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc12000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc12200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc12400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc12600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc12800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc12a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc12c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc12e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc13000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc13200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc13400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc13600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc13800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc13a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc13c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc13e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc14000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc14200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc14400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc14600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc14800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc14a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc14c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc14e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc15000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc15200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc15400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc15600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc15800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc15a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc15c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc15e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc16000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc16200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc16400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc16600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc16800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc16a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc16c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc16e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc17000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc17200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc17400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc17600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc17800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc17a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc17c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc17e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc18000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc18200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc18400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc18600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc18800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc18a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc18c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc18e00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc19000
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc19200
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc19400
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc19600
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc19800
proj187:3284234:3284798 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc19a00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc19c00
proj187:3284234:3284798 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc19e00
proj187:3284234:3284798 [0] NCCL INFO Connected all rings
proj187:3284234:3284798 [0] NCCL INFO Connected all trees
proj187:3284234:3284798 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3284234:3284799 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7f907c002f20
proj187:3284234:3284799 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-wUXT0K
proj187:3284234:3284799 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3284234:3284799 [0] NCCL INFO proxyProgressAsync opId=0x7f8f2407f520 op.type=1 op.reqBuff=0x7f907c000bb0 op.respSize=16 done
proj187:3284234:3284798 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f8f2407f520
proj187:3284234:3284799 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3284234:3284798 [0] NCCL INFO recvOpId=0x7f8f2407f520 matches expected opId=0x7f8f2407f520
proj187:3284234:3284798 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7f907c003160
proj187:3284234:3284799 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7f8f20000000
proj187:3284234:3284799 [0] NCCL INFO proxyProgressAsync opId=0x7f8f2407f520 op.type=2 op.reqBuff=0x7f907c005cc0 op.respSize=0 done
proj187:3284234:3284798 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f8f2407f520
proj187:3284234:3284799 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3284234:3284798 [0] NCCL INFO recvOpId=0x7f8f2407f520 matches expected opId=0x7f8f2407f520
proj187:3284234:3284798 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7f90afc1a000
proj187:3284234:3284798 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7f8f1e000000
proj187:3284234:3284798 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7f90dd470600
proj187:3284234:3284798 NCCL CALL ncclCommInitRank(0xdbf1a30, 1, 0x5302a2e6143095f, 0, 0)
proj187:3284234:3284798 [0] NCCL INFO comm 0xdbf1a30 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0x5302a2e6143095f - Init COMPLETE
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f902c000000 recvbuff 0x7f902c000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f902c000000,7f902c000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1328140288
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGetUniqueId(0xe706d28c92d5d536)
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO init.cc:1584 Cuda Host Alloc Size 4 pointer 0x7f90dd470800
proj187:3284234:3284818 [0] NCCL INFO Using network Socket
proj187:3284234:3284818 [0] NCCL INFO comm 0x191ff800 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xe706d28c92d5d536 - Init START
proj187:3284234:3284818 [0] NCCL INFO NET/Socket : GPU Direct RDMA Disabled for HCA 0 'ens81f0'
proj187:3284234:3284818 [0] NCCL INFO === System : maxBw 5000.0 totalBw 0.0 ===
proj187:3284234:3284818 [0] NCCL INFO CPU/1 (1/1/2)
proj187:3284234:3284818 [0] NCCL INFO + PCI[24.0] - PCI/C1000 (1000c01010000000)
proj187:3284234:3284818 [0] NCCL INFO               + PCI[24.0] - PCI/C8000 (1000c01010de13b8)
proj187:3284234:3284818 [0] NCCL INFO                             + PCI[24.0] - GPU/CA000 (0)
proj187:3284234:3284818 [0] NCCL INFO                                           + NVL[160.0] - NVS/0
proj187:3284234:3284818 [0] NCCL INFO + SYS[10.0] - CPU/0
proj187:3284234:3284818 [0] NCCL INFO CPU/0 (1/1/2)
proj187:3284234:3284818 [0] NCCL INFO + SYS[10.0] - CPU/1
proj187:3284234:3284818 [0] NCCL INFO + PCI[3.0] - NIC/17000
proj187:3284234:3284818 [0] NCCL INFO ==========================================
proj187:3284234:3284818 [0] NCCL INFO GPU/CA000 :GPU/CA000 (0/5000.000000/LOC) NVS/0 (1/160.000000/NVL) CPU/1 (3/24.000000/PHB) CPU/0 (4/10.000000/SYS) 
proj187:3284234:3284818 [0] NCCL INFO Setting affinity for GPU 7 to ffff0000,ffff0000
proj187:3284234:3284818 [0] NCCL INFO Pattern 4, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284818 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO Pattern 3, crossNic 0, nChannels 16, bw 40.000000/40.000000, type LOC/PIX, sameChannels 1
proj187:3284234:3284818 [0] NCCL INFO  0 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  1 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  2 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  3 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  4 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  5 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  6 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  7 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  8 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO  9 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 10 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 11 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 12 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 13 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 14 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO 15 : GPU/0
proj187:3284234:3284818 [0] NCCL INFO Tree 0 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 16 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 1 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 17 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 2 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 18 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 3 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 19 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 4 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 20 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 5 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 21 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 6 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 22 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 7 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 23 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 8 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 24 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 9 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 25 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 10 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 26 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 11 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 27 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 12 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 28 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 13 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 29 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 14 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 30 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 15 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Tree 31 : -1 -> 0 -> -1/-1/-1
proj187:3284234:3284818 [0] NCCL INFO Channel 00/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 01/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 02/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 03/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 04/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 05/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 06/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 07/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 08/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 09/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 10/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 11/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 12/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 13/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 14/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 15/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 16/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 17/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 18/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 19/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 20/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 21/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 22/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 23/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 24/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 25/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 26/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 27/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 28/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 29/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 30/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Channel 31/32 :    0
proj187:3284234:3284818 [0] NCCL INFO Ring 00 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 01 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 02 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 03 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 04 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 05 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 06 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 07 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 08 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 09 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 10 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 11 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 12 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 13 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 14 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 15 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 16 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 17 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 18 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 19 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 20 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 21 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 22 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 23 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 24 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 25 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 26 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 27 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 28 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 29 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 30 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Ring 31 : 0 -> 0 -> 0
proj187:3284234:3284818 [0] NCCL INFO Trees [0] -1/-1/-1->0->-1 [1] -1/-1/-1->0->-1 [2] -1/-1/-1->0->-1 [3] -1/-1/-1->0->-1 [4] -1/-1/-1->0->-1 [5] -1/-1/-1->0->-1 [6] -1/-1/-1->0->-1 [7] -1/-1/-1->0->-1 [8] -1/-1/-1->0->-1 [9] -1/-1/-1->0->-1 [10] -1/-1/-1->0->-1 [11] -1/-1/-1->0->-1 [12] -1/-1/-1->0->-1 [13] -1/-1/-1->0->-1 [14] -1/-1/-1->0->-1 [15] -1/-1/-1->0->-1 [16] -1/-1/-1->0->-1 [17] -1/-1/-1->0->-1 [18] -1/-1/-1->0->-1 [19] -1/-1/-1->0->-1 [20] -1/-1/-1->0->-1 [21] -1/-1/-1->0->-1 [22] -1/-1/-1->0->-1 [23] -1/-1/-1->0->-1 [24] -1/-1/-1->0->-1 [25] -1/-1/-1->0->-1 [26] -1/-1/-1->0->-1 [27] -1/-1/-1->0->-1 [28] -1/-1/-1->0->-1 [29] -1/-1/-1->0->-1 [30] -1/-1/-1->0->-1 [31] -1/-1/-1->0->-1
proj187:3284234:3284818 [0] NCCL INFO P2P Chunksize set to 131072
proj187:3284234:3284818 [0] NCCL INFO misc/utils.cc:235 memory stack hunk malloc(65536)
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5c800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5ca00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5cc00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5ce00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5d000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5d200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5d400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5d600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5d800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5da00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5dc00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5de00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5e000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5e200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5e400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5e600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5e800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5ea00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5ec00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5ee00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5f000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5f200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5f400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5f600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5f800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc5fa00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc5fc00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc5fe00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc60000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc60200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc60400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc60600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc60800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc60a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc60c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc60e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc61000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc61200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc61400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc61600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc61800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc61a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc61c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc61e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc62000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc62200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc62400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc62600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc62800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc62a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc62c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc62e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc63000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc63200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc63400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc63600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc63800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc63a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc63c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc63e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc64000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc64200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc64400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc64600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc64800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc64a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc64c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc64e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc65000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc65200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc65400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc65600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc65800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc65a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc65c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc65e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc66000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc66200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc66400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc66600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc66800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc66a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc66c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc66e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc67000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc67200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc67400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc67600
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc67800
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc67a00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc67c00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc67e00
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc68000
proj187:3284234:3284818 [0] NCCL INFO channel.cc:40 Cuda Alloc Size 384 pointer 0x7f90afc68200
proj187:3284234:3284818 [0] NCCL INFO channel.cc:43 Cuda Alloc Size 24 pointer 0x7f90afc68400
proj187:3284234:3284818 [0] NCCL INFO channel.cc:54 Cuda Alloc Size 4 pointer 0x7f90afc68600
proj187:3284234:3284818 [0] NCCL INFO Connected all rings
proj187:3284234:3284818 [0] NCCL INFO Connected all trees
proj187:3284234:3284818 [0] NCCL INFO 32 coll channels, 0 nvls channels, 32 p2p channels, 32 p2p channels per peer
proj187:3284234:3284819 [0] NCCL INFO Mem Realloc old size 0, new size 8 pointer 0x7f8a38002f20
proj187:3284234:3284819 [0] NCCL INFO Allocated 4194660 bytes of shared memory in /dev/shm/nccl-S1Sl0M
proj187:3284234:3284819 [0] NCCL INFO New proxy send connection 0 from local rank 0, transport 2
proj187:3284234:3284819 [0] NCCL INFO proxyProgressAsync opId=0x7f8a3c07f520 op.type=1 op.reqBuff=0x7f8a38000bb0 op.respSize=16 done
proj187:3284234:3284818 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f8a3c07f520
proj187:3284234:3284818 [0] NCCL INFO recvOpId=0x7f8a3c07f520 matches expected opId=0x7f8a3c07f520
proj187:3284234:3284819 [0] NCCL INFO Received and initiated operation=Init res=0
proj187:3284234:3284818 [0] NCCL INFO Connection to proxy localRank 0 -> connection 0x7f8a38003160
proj187:3284234:3284819 [0] NCCL INFO transport/net.cc:446 Cuda Alloc Size 67108864 pointer 0x7f8a2c000000
proj187:3284234:3284819 [0] NCCL INFO proxyProgressAsync opId=0x7f8a3c07f520 op.type=2 op.reqBuff=0x7f8a38005cc0 op.respSize=0 done
proj187:3284234:3284818 [0] NCCL INFO ncclPollProxyResponse Received new opId=0x7f8a3c07f520
proj187:3284234:3284819 [0] NCCL INFO Received and initiated operation=SharedInit res=0
proj187:3284234:3284818 [0] NCCL INFO recvOpId=0x7f8a3c07f520 matches expected opId=0x7f8a3c07f520
proj187:3284234:3284818 [0] NCCL INFO init.cc:387 Cuda Alloc Size 7728 pointer 0x7f90afc68800
proj187:3284234:3284818 [0] NCCL INFO init.cc:412 Cuda Host Alloc Size 33554432 pointer 0x7f8a36000000
proj187:3284234:3284818 [0] NCCL INFO init.cc:418 Cuda Host Alloc Size 128 pointer 0x7f90dd470a00
proj187:3284234:3284818 NCCL CALL ncclCommInitRank(0x191ff800, 1, 0xe706d28c92d5d536, 0, 0)
proj187:3284234:3284818 [0] NCCL INFO comm 0x191ff800 rank 0 nranks 1 cudaDev 0 nvmlDev 7 busId ca000 commId 0xe706d28c92d5d536 - Init COMPLETE
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd374a00 recvbuff 0x7f90dd374a00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd374a00,7f90dd374a00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 0, finish warm up ...
rank_id = 0, input_tensor_shapes: []
rank:0,cuda fwd time: 124.9112319946289
rank:0, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.24,timestamp=4409202101.07,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.29,timestamp=4409202112.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.82,timestamp=4409202121.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409202132.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.88,timestamp=4409202141.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.83,timestamp=4409202152.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.14,timestamp=4409202161.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.99,timestamp=4409202173.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409202181.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409202193.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409202203.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.69,timestamp=4409202215.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409202224.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 0, finish FWD profile ...
rank:0, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.21,timestamp=4409202239.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.89,timestamp=4409202265.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.18,timestamp=4409202281.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.56,timestamp=4409202307.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.91,timestamp=4409202324.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.48,timestamp=4409202349.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.94,timestamp=4409202366.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.39,timestamp=4409202391.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.92,timestamp=4409202408.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.65,timestamp=4409202434.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.45,timestamp=4409202451.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.88,timestamp=4409202477.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:0, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fca00 recvbuff 0x7f90dd3fca00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fca00,7f90dd3fca00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:0,optimizer_step time: 36.31001663208008
rank:0, finish optimizer.step profile ...
rank:0, Before memory release - Allocated: 21410941440, Reserved: 36066820096
rank:0, trace log has been written to txt...
rank:0, finish release GPU memory ...
rank:0, After memory release - Allocated: 10651599872, Reserved: 10783555584
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd374400 recvbuff 0x7f90dd374400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd374400,7f90dd374400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f8dba000000 recvbuff 0x7f8dba000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f8dba000000,7f8dba000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 0): 1328140288
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 1, finish warm up ...
rank_id = 1, input_tensor_shapes: []
rank:1,cuda fwd time: 123.7391357421875
rank:1, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409203509.86,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409203521.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.96,timestamp=4409203530.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.65,timestamp=4409203541.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409203550.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.14,timestamp=4409203561.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409203570.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409203582.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409203590.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.14,timestamp=4409203602.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409203611.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409203623.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.9,timestamp=4409203632.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 1, finish FWD profile ...
rank:1, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.94,timestamp=4409203646.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.68,timestamp=4409203672.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.24,timestamp=4409203689.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.41,timestamp=4409203714.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.19,timestamp=4409203731.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.37,timestamp=4409203757.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.19,timestamp=4409203773.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.77,timestamp=4409203799.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.54,timestamp=4409203816.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.92,timestamp=4409203842.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.41,timestamp=4409203859.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.78,timestamp=4409203885.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:1, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:1,optimizer_step time: 36.368385314941406
rank:1, finish optimizer.step profile ...
rank:1, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:1, trace log has been written to txt...
rank:1, finish release GPU memory ...
rank:1, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe800 recvbuff 0x7f90dd3fe800 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe800,7f90dd3fe800,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe800 recvbuff 0x7f90dd3fe800 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe800,7f90dd3fe800,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f902c000000 recvbuff 0x7f902c000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f902c000000,7f902c000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 0): 1328140288
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff000 recvbuff 0x7f90dd3ff000 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff000,7f90dd3ff000,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 2, finish warm up ...
rank_id = 2, input_tensor_shapes: []
rank:2,cuda fwd time: 123.01824188232422
rank:2, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409204906.45,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.89,timestamp=4409204918.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409204927.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.88,timestamp=4409204938.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.04,timestamp=4409204946.88,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.08,timestamp=4409204958.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409204966.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409204978.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409204986.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.38,timestamp=4409204998.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.85,timestamp=4409205006.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.3,timestamp=4409205019.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.85,timestamp=4409205028.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 2, finish FWD profile ...
rank:2, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.81,timestamp=4409205042.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.07,timestamp=4409205067.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.03,timestamp=4409205084.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.59,timestamp=4409205110.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.33,timestamp=4409205127.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.56,timestamp=4409205152.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409205169.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.58,timestamp=4409205195.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.95,timestamp=4409205212.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.4,timestamp=4409205237.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.45,timestamp=4409205254.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.84,timestamp=4409205280.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:2, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:2,optimizer_step time: 36.401153564453125
rank:2, finish optimizer.step profile ...
rank:2, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:2, trace log has been written to txt...
rank:2, finish release GPU memory ...
rank:2, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fea00 recvbuff 0x7f90dd3fea00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fea00,7f90dd3fea00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fee00 recvbuff 0x7f90dd3fee00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fee00,7f90dd3fee00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f8dba000000 recvbuff 0x7f8dba000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f8dba000000,7f8dba000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 0): 1328140288
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffe00 recvbuff 0x7f90dd3ffe00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffe00,7f90dd3ffe00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 3, finish warm up ...
rank_id = 3, input_tensor_shapes: []
rank:3,cuda fwd time: 125.06317138671875
rank:3, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.31,timestamp=4409206211.19,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.97,timestamp=4409206223.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409206231.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.99,timestamp=4409206243.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409206251.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.39,timestamp=4409206263.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409206272.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.03,timestamp=4409206284.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409206293.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.79,timestamp=4409206305.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409206314.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.78,timestamp=4409206326.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.38,timestamp=4409206335.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 3, finish FWD profile ...
rank:3, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.33,timestamp=4409206349.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.37,timestamp=4409206375.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.33,timestamp=4409206392.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.87,timestamp=4409206418.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.24,timestamp=4409206435.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.84,timestamp=4409206460.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.17,timestamp=4409206477.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.84,timestamp=4409206503.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.19,timestamp=4409206520.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.67,timestamp=4409206545.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.03,timestamp=4409206562.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.76,timestamp=4409206587.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:3, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffe00 recvbuff 0x7f90dd3ffe00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffe00,7f90dd3ffe00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:3,optimizer_step time: 36.190208435058594
rank:3, finish optimizer.step profile ...
rank:3, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:3, trace log has been written to txt...
rank:3, finish release GPU memory ...
rank:3, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff000 recvbuff 0x7f90dd3ff000 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff000,7f90dd3ff000,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff200 recvbuff 0x7f90dd3ff200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff200,7f90dd3ff200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff400 recvbuff 0x7f90dd3ff400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff400,7f90dd3ff400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f902c000000 recvbuff 0x7f902c000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f902c000000,7f902c000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffe00 recvbuff 0x7f90dd3ffe00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffe00,7f90dd3ffe00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 4, finish warm up ...
rank_id = 4, input_tensor_shapes: []
rank:4,cuda fwd time: 130.79849243164062
rank:4, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.36,timestamp=4409207554.81,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409207566.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.9,timestamp=4409207575.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.67,timestamp=4409207586.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409207595.28,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.18,timestamp=4409207606.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409207615.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=5.9,timestamp=4409207627.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409207636.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.5,timestamp=4409207648.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409207657.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.17,timestamp=4409207670.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.12,timestamp=4409207679.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 4, finish FWD profile ...
rank:4, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.02,timestamp=4409207698.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.42,timestamp=4409207723.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.79,timestamp=4409207740.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.65,timestamp=4409207765.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.19,timestamp=4409207782.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.49,timestamp=4409207807.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409207824.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409207850.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.28,timestamp=4409207867.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.58,timestamp=4409207892.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.46,timestamp=4409207909.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.81,timestamp=4409207935.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:4, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffe00 recvbuff 0x7f90dd3ffe00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffe00,7f90dd3ffe00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:4,optimizer_step time: 36.23833465576172
rank:4, finish optimizer.step profile ...
rank:4, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:4, trace log has been written to txt...
rank:4, finish release GPU memory ...
rank:4, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff600 recvbuff 0x7f90dd3ff600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff600,7f90dd3ff600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ff800 recvbuff 0x7f90dd3ff800 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ff800,7f90dd3ff800,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffa00 recvbuff 0x7f90dd3ffa00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffa00,7f90dd3ffa00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f8dba000000 recvbuff 0x7f8dba000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f8dba000000,7f8dba000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd2e8400 recvbuff 0x7f90dd2e8400 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd2e8400,7f90dd2e8400,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 5, finish warm up ...
rank_id = 5, input_tensor_shapes: []
rank:5,cuda fwd time: 124.15692901611328
rank:5, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.3,timestamp=4409208892.89,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.79,timestamp=4409208904.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.97,timestamp=4409208913.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.84,timestamp=4409208924.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.02,timestamp=4409208933.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.31,timestamp=4409208944.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409208953.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.94,timestamp=4409208965.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.39,timestamp=4409208974.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.72,timestamp=4409208986.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.83,timestamp=4409208994.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409209006.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.09,timestamp=4409209015.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 5, finish FWD profile ...
rank:5, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.19,timestamp=4409209030.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.23,timestamp=4409209055.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.11,timestamp=4409209072.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.87,timestamp=4409209098.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.16,timestamp=4409209115.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.6,timestamp=4409209140.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.0,timestamp=4409209157.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.71,timestamp=4409209182.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.18,timestamp=4409209199.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.58,timestamp=4409209225.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.2,timestamp=4409209241.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.53,timestamp=4409209267.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:5, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd2e8400 recvbuff 0x7f90dd2e8400 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd2e8400,7f90dd2e8400,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:5,optimizer_step time: 36.340736389160156
rank:5, finish optimizer.step profile ...
rank:5, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:5, trace log has been written to txt...
rank:5, finish release GPU memory ...
rank:5, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffc00 recvbuff 0x7f90dd3ffc00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffc00,7f90dd3ffc00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffe00 recvbuff 0x7f90dd3ffe00 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffe00,7f90dd3ffe00,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd200200 recvbuff 0x7f90dd200200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd200200,7f90dd200200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f902c000000 recvbuff 0x7f902c000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f902c000000,7f902c000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3ffc00 recvbuff 0x7f90dd3ffc00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3ffc00,7f90dd3ffc00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 6, finish warm up ...
rank_id = 6, input_tensor_shapes: []
rank:6,cuda fwd time: 124.41088104248047
rank:6, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.29,timestamp=4409210276.5,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.42,timestamp=4409210288.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409210297.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.68,timestamp=4409210308.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409210317.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.81,timestamp=4409210328.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409210337.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409210348.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.12,timestamp=4409210357.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.13,timestamp=4409210369.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.91,timestamp=4409210377.83,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.73,timestamp=4409210389.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.83,timestamp=4409210398.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 6, finish FWD profile ...
rank:6, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.36,timestamp=4409210414.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.05,timestamp=4409210440.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=15.95,timestamp=4409210456.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409210482.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.18,timestamp=4409210499.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.65,timestamp=4409210524.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409210541.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409210567.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.35,timestamp=4409210584.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409210609.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.28,timestamp=4409210626.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.57,timestamp=4409210652.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:6, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fea00 recvbuff 0x7f90dd3fea00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fea00,7f90dd3fea00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:6,optimizer_step time: 36.46156692504883
rank:6, finish optimizer.step profile ...
rank:6, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:6, trace log has been written to txt...
rank:6, finish release GPU memory ...
rank:6, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8400 recvbuff 0x7f90dd3f8400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8400,7f90dd3f8400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8400 recvbuff 0x7f90dd3f8400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8400,7f90dd3f8400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f8dba000000 recvbuff 0x7f8dba000000 count 103022592 datatype 7 op 0 root 0 comm 0xdbf1a30 [nranks=1] stream 0x8cd9700
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f8dba000000,7f8dba000000,103022592,7,0,0,0xdbf1a30,0x8cd9700)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1328140288 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.word_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    embedding.position_embeddings.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fea00 recvbuff 0x7f90dd3fea00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fea00,7f90dd3fea00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 7, finish warm up ...
rank_id = 7, input_tensor_shapes: []
rank:7,cuda fwd time: 125.3017578125
rank:7, fwd_subop num: 13, fwd_subop: ['trace_src_func=_reduce,duration=0.24,timestamp=4409211706.77,input__shape=[2, 2048, 8192],input__dtype=torch.float32,func_name=embedding_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409211718.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409211727.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.51,timestamp=4409211739.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.05,timestamp=4409211747.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.72,timestamp=4409211759.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409211768.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.46,timestamp=4409211779.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409211788.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.16,timestamp=4409211800.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.04,timestamp=4409211809.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.77,timestamp=4409211821.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.63,timestamp=4409211830.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 7, finish FWD profile ...
rank:7, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.18,timestamp=4409211845.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.93,timestamp=4409211870.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.26,timestamp=4409211887.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.54,timestamp=4409211912.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.33,timestamp=4409211929.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.79,timestamp=4409211955.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.56,timestamp=4409211972.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.98,timestamp=4409211998.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.34,timestamp=4409212015.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.83,timestamp=4409212041.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409212057.95,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.79,timestamp=4409212083.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:7, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fea00 recvbuff 0x7f90dd3fea00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fea00,7f90dd3fea00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:7,optimizer_step time: 36.51174545288086
rank:7, finish optimizer.step profile ...
rank:7, Before memory release - Allocated: 32037112320, Reserved: 46749712384
rank:7, trace log has been written to txt...
rank:7, finish release GPU memory ...
rank:7, After memory release - Allocated: 10651599872, Reserved: 21344813056
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 1): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 8, finish warm up ...
rank_id = 8, input_tensor_shapes: [(2048, 2, 8192)]
rank:8,cuda fwd time: 122.19699096679688
rank:8, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=9.51,timestamp=4409213339.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.87,timestamp=4409213348.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409213359.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.97,timestamp=4409213368.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.48,timestamp=4409213379.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.75,timestamp=4409213388.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409213400.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409213408.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.18,timestamp=4409213420.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409213429.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.04,timestamp=4409213441.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409213450.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 8, finish FWD profile ...
rank:8, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.07,timestamp=4409213464.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.91,timestamp=4409213490.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.32,timestamp=4409213507.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.58,timestamp=4409213532.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.24,timestamp=4409213549.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.53,timestamp=4409213575.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.62,timestamp=4409213592.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.98,timestamp=4409213618.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.59,timestamp=4409213635.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.86,timestamp=4409213661.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409213678.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.71,timestamp=4409213703.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:8, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:8,optimizer_step time: 32.94617462158203
rank:8, finish optimizer.step profile ...
rank:8, Before memory release - Allocated: 30387702272, Reserved: 44702892032
rank:8, trace log has been written to txt...
rank:8, finish release GPU memory ...
rank:8, After memory release - Allocated: 20586759168, Reserved: 21133000704
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 1): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 9, finish warm up ...
rank_id = 9, input_tensor_shapes: [(2048, 2, 8192)]
rank:9,cuda fwd time: 121.37983703613281
rank:9, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=7.87,timestamp=4409214999.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.87,timestamp=4409215008.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409215019.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409215027.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.68,timestamp=4409215038.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409215047.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409215058.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409215067.52,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.05,timestamp=4409215079.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.89,timestamp=4409215088.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.13,timestamp=4409215100.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.9,timestamp=4409215108.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 9, finish FWD profile ...
rank:9, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.03,timestamp=4409215123.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.81,timestamp=4409215148.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.3,timestamp=4409215165.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.57,timestamp=4409215191.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.33,timestamp=4409215208.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.59,timestamp=4409215233.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.41,timestamp=4409215250.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.89,timestamp=4409215276.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.49,timestamp=4409215293.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.9,timestamp=4409215319.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.51,timestamp=4409215336.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.01,timestamp=4409215362.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:9, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:9,optimizer_step time: 32.9799690246582
rank:9, finish optimizer.step profile ...
rank:9, Before memory release - Allocated: 40323435008, Reserved: 54895050752
rank:9, trace log has been written to txt...
rank:9, finish release GPU memory ...
rank:9, After memory release - Allocated: 20587332608, Reserved: 30599544832
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 1): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 10, finish warm up ...
rank_id = 10, input_tensor_shapes: [(2048, 2, 8192)]
rank:10,cuda fwd time: 121.5467529296875
rank:10, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=7.95,timestamp=4409216606.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.84,timestamp=4409216615.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.64,timestamp=4409216626.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409216635.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.66,timestamp=4409216646.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409216654.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409216665.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409216674.46,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409216686.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409216695.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409216707.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409216716.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 10, finish FWD profile ...
rank:10, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.19,timestamp=4409216730.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.07,timestamp=4409216756.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.44,timestamp=4409216773.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.94,timestamp=4409216799.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.86,timestamp=4409216817.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.25,timestamp=4409216843.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.89,timestamp=4409216860.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.27,timestamp=4409216886.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.3,timestamp=4409216903.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.76,timestamp=4409216929.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.16,timestamp=4409216946.12,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.66,timestamp=4409216971.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:10, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:10,optimizer_step time: 33.01580810546875
rank:10, finish optimizer.step profile ...
rank:10, Before memory release - Allocated: 40323435008, Reserved: 54895050752
rank:10, trace log has been written to txt...
rank:10, finish release GPU memory ...
rank:10, After memory release - Allocated: 20586759168, Reserved: 30599544832
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 1): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 11, finish warm up ...
rank_id = 11, input_tensor_shapes: [(2048, 2, 8192)]
rank:11,cuda fwd time: 123.49030303955078
rank:11, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.24,timestamp=4409218185.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409218194.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.86,timestamp=4409218205.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409218214.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.15,timestamp=4409218225.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.36,timestamp=4409218234.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.18,timestamp=4409218246.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409218255.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.87,timestamp=4409218267.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409218276.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.88,timestamp=4409218288.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409218297.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 11, finish FWD profile ...
rank:11, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.45,timestamp=4409218312.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.57,timestamp=4409218338.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.44,timestamp=4409218355.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.89,timestamp=4409218381.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.25,timestamp=4409218398.15,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.86,timestamp=4409218423.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.18,timestamp=4409218440.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.82,timestamp=4409218466.36,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.16,timestamp=4409218483.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.6,timestamp=4409218508.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409218525.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.7,timestamp=4409218551.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:11, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:11,optimizer_step time: 32.94822311401367
rank:11, finish optimizer.step profile ...
rank:11, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:11, trace log has been written to txt...
rank:11, finish release GPU memory ...
rank:11, After memory release - Allocated: 20587332608, Reserved: 30867980288
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 12, finish warm up ...
rank_id = 12, input_tensor_shapes: [(2048, 2, 8192)]
rank:12,cuda fwd time: 122.3720932006836
rank:12, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.76,timestamp=4409219722.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.89,timestamp=4409219731.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.82,timestamp=4409219742.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409219751.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.98,timestamp=4409219762.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409219771.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.78,timestamp=4409219782.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409219791.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.63,timestamp=4409219803.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409219812.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409219824.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.19,timestamp=4409219833.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 12, finish FWD profile ...
rank:12, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.27,timestamp=4409219847.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.08,timestamp=4409219873.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.45,timestamp=4409219890.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.68,timestamp=4409219916.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.0,timestamp=4409219932.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.55,timestamp=4409219958.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.47,timestamp=4409219975.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.98,timestamp=4409220001.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.51,timestamp=4409220018.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.03,timestamp=4409220044.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.23,timestamp=4409220061.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.76,timestamp=4409220086.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:12, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:12,optimizer_step time: 32.926719665527344
rank:12, finish optimizer.step profile ...
rank:12, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:12, trace log has been written to txt...
rank:12, finish release GPU memory ...
rank:12, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 13, finish warm up ...
rank_id = 13, input_tensor_shapes: [(2048, 2, 8192)]
rank:13,cuda fwd time: 120.73779296875
rank:13, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.85,timestamp=4409221263.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409221271.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.9,timestamp=4409221283.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409221291.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.0,timestamp=4409221302.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409221311.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409221322.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.98,timestamp=4409221331.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.33,timestamp=4409221342.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409221351.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.61,timestamp=4409221363.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409221372.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 13, finish FWD profile ...
rank:13, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.19,timestamp=4409221386.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.0,timestamp=4409221412.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409221429.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.48,timestamp=4409221454.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.34,timestamp=4409221471.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409221497.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.28,timestamp=4409221514.11,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.59,timestamp=4409221539.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.24,timestamp=4409221556.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.72,timestamp=4409221582.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.3,timestamp=4409221598.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.89,timestamp=4409221624.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:13, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:13,optimizer_step time: 32.93900680541992
rank:13, finish optimizer.step profile ...
rank:13, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:13, trace log has been written to txt...
rank:13, finish release GPU memory ...
rank:13, After memory release - Allocated: 20587332608, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 14, finish warm up ...
rank_id = 14, input_tensor_shapes: [(2048, 2, 8192)]
rank:14,cuda fwd time: 130.5927734375
rank:14, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.84,timestamp=4409222811.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409222820.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.92,timestamp=4409222831.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.97,timestamp=4409222839.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.07,timestamp=4409222851.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.1,timestamp=4409222859.86,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409222871.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409222880.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.61,timestamp=4409222891.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.08,timestamp=4409222910.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.32,timestamp=4409222921.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409222930.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 14, finish FWD profile ...
rank:14, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.93,timestamp=4409222944.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.85,timestamp=4409222970.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.22,timestamp=4409222987.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.57,timestamp=4409223012.82,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.34,timestamp=4409223029.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.75,timestamp=4409223055.41,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.49,timestamp=4409223072.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409223098.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.35,timestamp=4409223114.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.55,timestamp=4409223140.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409223157.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.18,timestamp=4409223183.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:14, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:14,optimizer_step time: 32.8355827331543
rank:14, finish optimizer.step profile ...
rank:14, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:14, trace log has been written to txt...
rank:14, finish release GPU memory ...
rank:14, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 15, finish warm up ...
rank_id = 15, input_tensor_shapes: [(2048, 2, 8192)]
rank:15,cuda fwd time: 123.6121597290039
rank:15, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.76,timestamp=4409224352.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409224360.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.86,timestamp=4409224372.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.97,timestamp=4409224380.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.3,timestamp=4409224392.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409224400.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.82,timestamp=4409224412.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.27,timestamp=4409224421.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.91,timestamp=4409224433.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.28,timestamp=4409224443.01,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.52,timestamp=4409224454.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.16,timestamp=4409224464.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 15, finish FWD profile ...
rank:15, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.02,timestamp=4409224478.54,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.26,timestamp=4409224504.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.85,timestamp=4409224521.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.22,timestamp=4409224548.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.87,timestamp=4409224565.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.02,timestamp=4409224591.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.24,timestamp=4409224608.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.72,timestamp=4409224634.0,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.2,timestamp=4409224650.79,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.73,timestamp=4409224676.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409224693.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.59,timestamp=4409224718.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:15, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:15,optimizer_step time: 32.972801208496094
rank:15, finish optimizer.step profile ...
rank:15, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:15, trace log has been written to txt...
rank:15, finish release GPU memory ...
rank:15, After memory release - Allocated: 20587332608, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (0, 2): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 16, finish warm up ...
rank_id = 16, input_tensor_shapes: [(2048, 2, 8192)]
rank:16,cuda fwd time: 120.50227355957031
rank:16, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.65,timestamp=4409225961.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.86,timestamp=4409225969.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.6,timestamp=4409225981.02,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409225989.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.56,timestamp=4409226000.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409226009.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409226020.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.74,timestamp=4409226029.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409226040.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.72,timestamp=4409226049.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.97,timestamp=4409226061.33,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.76,timestamp=4409226069.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 16, finish FWD profile ...
rank:16, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.72,timestamp=4409226083.92,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.26,timestamp=4409226109.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.23,timestamp=4409226126.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.55,timestamp=4409226152.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.32,timestamp=4409226169.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.56,timestamp=4409226194.59,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.34,timestamp=4409226211.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.53,timestamp=4409226236.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409226253.72,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.53,timestamp=4409226279.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.33,timestamp=4409226296.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.51,timestamp=4409226321.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:16, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:16,optimizer_step time: 33.137664794921875
rank:16, finish optimizer.step profile ...
rank:16, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:16, trace log has been written to txt...
rank:16, finish release GPU memory ...
rank:16, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (1, 2): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 17, finish warm up ...
rank_id = 17, input_tensor_shapes: [(2048, 2, 8192)]
rank:17,cuda fwd time: 121.26617431640625
rank:17, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.85,timestamp=4409227499.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409227508.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.88,timestamp=4409227519.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.01,timestamp=4409227528.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=9.06,timestamp=4409227539.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409227547.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.5,timestamp=4409227559.34,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409227568.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.45,timestamp=4409227580.05,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409227588.87,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409227600.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.02,timestamp=4409227609.44,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 17, finish FWD profile ...
rank:17, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.99,timestamp=4409227623.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.27,timestamp=4409227649.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409227666.31,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.81,timestamp=4409227692.04,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.15,timestamp=4409227708.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.68,timestamp=4409227734.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.17,timestamp=4409227751.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.41,timestamp=4409227776.45,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.09,timestamp=4409227793.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.42,timestamp=4409227818.51,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.1,timestamp=4409227835.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.6,timestamp=4409227860.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:17, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:17,optimizer_step time: 32.92057418823242
rank:17, finish optimizer.step profile ...
rank:17, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:17, trace log has been written to txt...
rank:17, finish release GPU memory ...
rank:17, After memory release - Allocated: 20587332608, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (2, 2): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 18, finish warm up ...
rank_id = 18, input_tensor_shapes: [(2048, 2, 8192)]
rank:18,cuda fwd time: 122.94143676757812
rank:18, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.59,timestamp=4409229093.03,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.87,timestamp=4409229101.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409229112.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409229121.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.77,timestamp=4409229132.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.23,timestamp=4409229141.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409229153.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409229162.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.35,timestamp=4409229174.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409229183.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409229195.22,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409229204.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 18, finish FWD profile ...
rank:18, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.26,timestamp=4409229218.64,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.45,timestamp=4409229244.69,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.45,timestamp=4409229261.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.01,timestamp=4409229287.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.2,timestamp=4409229304.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.87,timestamp=4409229330.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409229347.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.91,timestamp=4409229372.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.7,timestamp=4409229390.18,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.95,timestamp=4409229416.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.63,timestamp=4409229433.39,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.75,timestamp=4409229459.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:18, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:18,optimizer_step time: 33.01273727416992
rank:18, finish optimizer.step profile ...
rank:18, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:18, trace log has been written to txt...
rank:18, finish release GPU memory ...
rank:18, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
 > number of parameters on (tensor, pipeline) model parallel rank (3, 2): 1208340480
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 19, finish warm up ...
rank_id = 19, input_tensor_shapes: [(2048, 2, 8192)]
rank:19,cuda fwd time: 120.77875518798828
rank:19, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.66,timestamp=4409230702.13,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.87,timestamp=4409230710.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.59,timestamp=4409230721.94,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409230730.49,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.66,timestamp=4409230741.66,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.99,timestamp=4409230750.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409230761.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.74,timestamp=4409230770.27,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.05,timestamp=4409230781.98,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.82,timestamp=4409230790.74,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.06,timestamp=4409230802.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.83,timestamp=4409230811.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 19, finish FWD profile ...
rank:19, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.96,timestamp=4409230825.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.64,timestamp=4409230850.78,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.22,timestamp=4409230867.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.79,timestamp=4409230893.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.17,timestamp=4409230910.07,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.83,timestamp=4409230935.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.2,timestamp=4409230952.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.76,timestamp=4409230978.24,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.29,timestamp=4409230995.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.62,timestamp=4409231020.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409231037.61,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.64,timestamp=4409231063.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:19, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:19,optimizer_step time: 32.9881591796875
rank:19, finish optimizer.step profile ...
rank:19, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:19, trace log has been written to txt...
rank:19, finish release GPU memory ...
rank:19, After memory release - Allocated: 20587332608, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 20, finish warm up ...
rank_id = 20, input_tensor_shapes: [(2048, 2, 8192)]
rank:20,cuda fwd time: 125.32530975341797
rank:20, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.67,timestamp=4409232314.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.87,timestamp=4409232322.84,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.03,timestamp=4409232334.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409232343.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=6.65,timestamp=4409232354.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.41,timestamp=4409232363.93,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.43,timestamp=4409232375.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.27,timestamp=4409232384.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=4.38,timestamp=4409232397.75,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.11,timestamp=4409232406.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.37,timestamp=4409232418.77,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.08,timestamp=4409232427.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 20, finish FWD profile ...
rank:20, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.26,timestamp=4409232442.19,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.1,timestamp=4409232467.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.58,timestamp=4409232485.1,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.03,timestamp=4409232511.06,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.55,timestamp=4409232528.23,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=25.02,timestamp=4409232554.25,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.32,timestamp=4409232571.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.91,timestamp=4409232596.97,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.17,timestamp=4409232613.71,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.95,timestamp=4409232639.56,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.31,timestamp=4409232656.48,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.82,timestamp=4409232682.21,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:20, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:20,optimizer_step time: 33.00454330444336
rank:20, finish optimizer.step profile ...
rank:20, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:20, trace log has been written to txt...
rank:20, finish release GPU memory ...
rank:20, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 21, finish warm up ...
rank_id = 21, input_tensor_shapes: [(2048, 2, 8192)]
rank:21,cuda fwd time: 123.74937438964844
rank:21, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.49,timestamp=4409233940.91,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.85,timestamp=4409233949.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.55,timestamp=4409233960.73,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.93,timestamp=4409233969.3,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.94,timestamp=4409233980.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.21,timestamp=4409233989.6,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.25,timestamp=4409234001.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.07,timestamp=4409234010.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.44,timestamp=4409234022.43,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.21,timestamp=4409234031.55,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.47,timestamp=4409234043.68,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.22,timestamp=4409234052.81,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 21, finish FWD profile ...
rank:21, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=12.1,timestamp=4409234067.5,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.23,timestamp=4409234093.57,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.06,timestamp=4409234110.35,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.75,timestamp=4409234136.09,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.12,timestamp=4409234152.89,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.83,timestamp=4409234178.62,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.17,timestamp=4409234195.38,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.91,timestamp=4409234221.17,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409234238.14,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.59,timestamp=4409234263.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409234280.58,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.6,timestamp=4409234306.08,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:21, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:21,optimizer_step time: 32.991233825683594
rank:21, finish optimizer.step profile ...
rank:21, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:21, trace log has been written to txt...
rank:21, finish release GPU memory ...
rank:21, After memory release - Allocated: 20587332608, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe600 recvbuff 0x7f90dd3fe600 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe600,7f90dd3fe600,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank_id = 22, finish warm up ...
rank_id = 22, input_tensor_shapes: [(2048, 2, 8192)]
rank:22,cuda fwd time: 121.11666870117188
rank:22, fwd_subop num: 12, fwd_subop: ['trace_src_func=allreduce,duration=8.67,timestamp=4409235571.85,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.86,timestamp=4409235580.47,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.58,timestamp=4409235591.65,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.94,timestamp=4409235600.2,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.03,timestamp=4409235611.37,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409235619.96,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.98,timestamp=4409235631.29,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.79,timestamp=4409235639.99,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.17,timestamp=4409235651.8,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.91,timestamp=4409235660.63,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=8.15,timestamp=4409235672.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=7.92,timestamp=4409235681.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=linear_fwd,group=tp,comm_func=allreduce']
rank_id = 22, finish FWD profile ...
rank:22, bwd_subop num: 12, bwd_subop: ['trace_src_func=allreduce,duration=11.94,timestamp=4409235695.4,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=23.67,timestamp=4409235720.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.21,timestamp=4409235737.53,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.96,timestamp=4409235763.42,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.12,timestamp=4409235780.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.85,timestamp=4409235805.9,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.19,timestamp=4409235822.67,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.75,timestamp=4409235848.32,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.35,timestamp=4409235865.26,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.6,timestamp=4409235890.76,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=16.36,timestamp=4409235907.7,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce', 'trace_src_func=allreduce,duration=24.58,timestamp=4409235933.16,input__shape=[4096, 8192],input__dtype=torch.float32,func_name=normlinear_bwd,group=tp,comm_func=allreduce']
rank:22, finish BWD profile ...
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fec00 recvbuff 0x7f90dd3fec00 count 1 datatype 7 op 0 root 0 comm 0x191ff800 [nranks=1] stream 0x8ce2680
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fec00,7f90dd3fec00,1,7,0,0,0x191ff800,0x8ce2680)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
rank:22,optimizer_step time: 32.95027160644531
rank:22, finish optimizer.step profile ...
rank:22, Before memory release - Allocated: 40323435008, Reserved: 54626615296
rank:22, trace log has been written to txt...
rank:22, finish release GPU memory ...
rank:22, After memory release - Allocated: 20586759168, Reserved: 30800871424
> building train, validation, and test datasets ...
 > datasets target sizes (minimum size):
    train:      40
    validation: 4
    test:       4
INFO:megatron.core.datasets.blended_megatron_dataset_config:mock = False
INFO:megatron.core.datasets.blended_megatron_dataset_config:Let split_matrix = [(0, 0.949), (0.949, 0.999), (0.999, 1.0)]
> building train, validation, and test datasets for GPT ...
WARNING:megatron.core.datasets.blended_megatron_dataset_builder:Building dataset splits with cls=GPTDataset, sizes=(40, 4, 4), and config=GPTDatasetConfig(random_seed=1234, sequence_length=2048, blend=(['/research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document'], None), blend_per_split=[None, None, None], split='949,50,1', split_matrix=[(0, 0.949), (0.949, 0.999), (0.999, 1.0)], path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<megatron.training.tokenizer.tokenizer._GPT2BPETokenizer object at 0x7f9162727880>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=True)
INFO:megatron.core.datasets.indexed_dataset:Load the _IndexReader from /research/d1/gds/ytyang/yichengfeng/Megatron-LM/data/output_prefix_gpt2/my-gpt2_text_document.idx
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence lengths
INFO:megatron.core.datasets.indexed_dataset:	Extract the sequence pointers
INFO:megatron.core.datasets.indexed_dataset:	Extract the document indices
INFO:megatron.core.datasets.indexed_dataset:> total number of sequences: 79000
INFO:megatron.core.datasets.indexed_dataset:> total number of documents: 79000
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset train indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 5e1e11971ef40f8dc73a2ef88be465ab-GPTDataset-train-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 108411
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset valid indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from 110f523a905a9a1bc24b200899db174e-GPTDataset-valid-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 5789
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3f8200 recvbuff 0x7f90dd3f8200 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3f8200,7f90dd3f8200,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
INFO:megatron.core.datasets.gpt_dataset:Load the GPTDataset test indices
INFO:megatron.core.datasets.gpt_dataset:	Load the document index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-document_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the sample index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-sample_index.npy
INFO:megatron.core.datasets.gpt_dataset:	Load the shuffle index from f095252d24c4530dc562c92b8b082e5a-GPTDataset-test-shuffle_index.npy
INFO:megatron.core.datasets.gpt_dataset:> total number of samples: 184
proj187:3284234:3284234 NCCL CALL ncclGroupStart()
proj187:3284234:3284234 [0] NCCL INFO AllReduce: opCount 0 sendbuff 0x7f90dd3fe400 recvbuff 0x7f90dd3fe400 count 1 datatype 1 op 0 root 0 comm 0x8cc2b40 [nranks=1] stream 0x84d2a50
proj187:3284234:3284234 NCCL CALL ncclAllReduce(7f90dd3fe400,7f90dd3fe400,1,1,0,0,0x8cc2b40,0x84d2a50)
proj187:3284234:3284234 NCCL CALL ncclGroupEnd()
> finished creating GPT datasets ...
building GPT model ...
args.is_scaling_mode:True
use mcore models, use_te = True
INFO:megatron.core.distributed.distributed_data_parallel:Setting up DistributedDataParallel with DistributedDataParallelConfig: DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, use_distributed_optimizer=False, check_for_nan_in_grad=True, bucket_size=None)
INFO:megatron.core.distributed.param_and_grad_buffer:Number of buckets for gradient all-reduce / reduce-scatter: 1
INFO:megatron.core.distributed.param_and_grad_buffer:Params for bucket 1 (1208340480 elements):
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc2.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc1.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.5.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.4.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.mlp.linear_fc2.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_proj.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.mlp.linear_fc1.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.3.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.layer_norm_weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_qkv.layer_norm_bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.2.self_attention.linear_proj.bias
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.1.self_attention.linear_qkv.weight
INFO:megatron.core.distributed.param_and_grad_buffer:    decoder.layers.0.mlp.linear_fc1.layer_norm_weight
INFO:megatron.core.optimizer:Setting up optimizer with OptimizerConfig: OptimizerConfig(optimizer='adam', lr=0.00015, min_lr=1e-05, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=False, params_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.999, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=False, overlap_grad_reduce=False, overlap_param_gather=False, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=True, timers=<megatron.core.timers.Timers object at 0x7f9162782820>)
> learning rate decay style: cosine
